# Глава 9
## Вопросы эффективности

> Программист на Лиспе знает значение всего, но не знает цены ничему.

> -Alan J.
Perlis

> Lisp по своей сути не менее эффективен, чем другие языки высокого уровня

> -Richard J.
Fateman

Одна из причин, по которой Lisp имеет долгую историю, заключается в том, что это идеальный язык для того, что сейчас называется *быстрое прототипирование* - быстрая разработка программы, не обращающая внимание на детали.
Именно этим мы и занимались до сих пор в этой книге: концентрировались на получении работающего алгоритма.
К сожалению, когда прототип должен быть превращен в программу производственного качества, детали уже нельзя игнорировать.
Большинство "настоящих" программ ИИ работают с большими объемами данных и с большими пространствами поиска.
Таким образом, соображения эффективности становятся очень важными.

Однако это не означает, что написание эффективной программы в корне отличается от написания рабочей программы.
В идеале разработка эффективной программы должна состоять из трех этапов.
Во-первых, разработайте рабочую программу, используя надлежащие абстракции, чтобы при необходимости ее можно было легко изменить.
Во-вторых, *проанализируйте* программу, чтобы определить, где она проводит большую часть времени.
В-третьих, замените медленные части более быстрыми версиями, сохранив при этом корректность программы.

Термин *эффективность* будет использоваться в основном для обозначения *скорости* или времени выполнения программы.
В меньшей степени *эффективность* также используется для обозначения *пространства* или объема памяти, потребляемого программой.
Также поговорим о стоимости программы.
Отчасти это связано с использованием метафоры "время - деньги", а отчасти связано с реальными денежными затратами: если критически важная программа работает неприемлемо медленно, возможно, вам придется купить более дорогой компьютер.

Lisp получил репутацию "неэффективного языка". Строго говоря, нет смысла называть *язык* эффективным или неэффективным.
Скорее, только конкретная *реализация* языка, выполняющего конкретную программу, может быть измерена на эффективность.
Утверждение о неэффективности Lisp отчасти является историческим утверждением: некоторые прошлые реализации *были* неэффективными.
Это также отчасти прогноз: есть несколько причин, по которым будущие реализации, как ожидается, будут иметь неэффективность.
Эти причины в основном проистекают из гибкости Lisp.
Lisp позволяет отложить принятие многих решений до времени выполнения, и это может увеличить время выполнения.
За последнее десятилетие "разрыв в эффективности" между Lisp и "традиционными языками", такими как FORTRAN или C, сократился.
Вот причины - некоторые заслуженные, а некоторые нет - создающие Лиспу репутацию неэффективного языка:

*   Ранние реализации скорее интерпретировались, чем компилировались, что делало их по сути неэффективными.
Реализации Common Lisp имеют компиляторы, так что это больше не проблема.
Хотя Lisp (в первую очередь) больше не является интерпретируемым языком, он по-прежнему является *интерактивным* языком, поэтому он сохраняет свою гибкость.

*   Лисп часто использовался для написания интерпретаторов для встроенных языков, что усугубляло проблему.
Рассмотрим эту цитату из книги [Cooper and Wogrin's (1988)](B9780080571157500285.xhtml#bb0260) о языке программирования на основе правил OPS5:

> Эффективность реализаций, компилирующих правила в исполняемый код, выгодно отличается от эффективности программ, написанных на большинстве последовательных языков, таких как FORTRAN или Pascal. Реализации, которые компилируют правила в структуры данных для интерпретации, как и многие из основанных на Lisp, могут быть заметно медленнее.

Здесь Лисп виноват по ассоциации.
Ошибочная цепочка рассуждений такова: Лисп использовался для написания интерпретаторов; интерпретаторы медлительны; поэтому Лисп медленный.
Хотя это правда, что Lisp очень упрощает написание интерпретаторов, он также упрощает написание компиляторов.
Эта книга - первая книга, в которой основное внимание уделяется использованию Lisp в качестве языка реализации и целевого языка для компиляторов.

*   Lisp поощряет стиль с множеством вызовов функций, особенно рекурсивных вызовов.
В некоторых старых системах вызовы функций были дорогими.
Но теперь понятно, что вызов функции может быть скомпилирован в простую инструкцию ветвления, и что многие рекурсивные вызовы могут выполняться не дороже, чем эквивалентный итерационный цикл (см. [Глава 22] (B9780080571157500224.xhtml)).
Также можно дать указание компилятору Common Lisp скомпилировать определенные функции во встроенном режиме(inline), чтобы не было дополнительных затрат на вызовы.
С другой стороны, многие системы Lisp требуют двух выборок вместо одной, чтобы найти код функции, и, следовательно, будут медленнее.
Этот дополнительный уровень косвенности - это плата за свободу переопределения функций без перезагрузки всей программы.

*   Проверка типов во время выполнения выполняется медленно.
Lisp предоставляет набор обобщенных функций.
Например, мы можем написать `(+ x y)`, не беспокоясь о том, являются ли `x` и `y` целыми числами, числами с плавающей запятой, большими числами, комплексными числами, рациональными числами или какой-либо комбинацией вышеперечисленного.
Это очень удобно, но это означает, что проверки типов должны выполняться во время выполнения, поэтому обобщенный + будет медленнее, чем, скажем, сложение 16-битных целых чисел без проверки переполнения.
Если важна эффективность, Common Lisp позволяет программисту включать объявления, которые могут исключить проверки во время выполнения.
Фактически, после добавления правильных объявлений Lisp может работать так же быстро или быстрее, как и обычные языки.
[Fateman (1973)](B9780080571157500285.xhtml#bb0375) сравнил процедуру кубичесого корня FORTRAN на PDP-10 с транслитерацией MacLisp.
Версия MacLisp выдавала практически идентичный числовой код, но в целом была на 18% быстрее из-за превосходной последовательности вызова функций. [1](#fn0010) Эпиграф в начале этой главы взят из этой статьи.
[Berlin and Weise (1990)](B9780080571157500285.xhtml#bb0085) в которой показывают, что с помощью специальной техники компиляции, называемой *частичным вычислением*, можно достичь скорости от 7 до 90 раз быстрее, чем код, скомпилированный традиционным способом.
Конечно, частичное вычисление можно использовать на любом языке, но в Лиспе это очень легко сделать.
Факт остается фактом: объекты Lisp должны каким-то образом представлять свой тип, и даже с объявлениями не все эти накладные расходы можно устранить.
Большинство реализаций Lisp оптимизируют доступ к спискам и фиксированным числам, но расплачиваются за другие, менее часто используемые типы данных.

*   Lisp автоматически управляет хранилищем, поэтому он должен переодически останавливаться и собирать неиспользуемое хранилище, или *мусор/garbage*.
В ранних системах это делалось путем периодической очистки всей памяти, что приводило к заметной паузе.
Современные системы, как правило, используют методы инкрементной(постепенной) сборки мусора, поэтому паузы короче и обычно незаметны(хотя паузы могут быть слишком длинными для приложений реального времени, таких как управление лабораторным прибором).
Проблема с автоматической сборкой мусора в наши дни не в том, что она медленная - на самом деле, автоматические системы делают примерно так же, как и ручное выделение.
Проблема в том, что они в первую очередь позволяют программисту создавать МНОГО мусора.
Программисты использующие традиционные языки, которым приходится убирать свой собственный мусор, как правило, более осторожны и чаще используют статическое, а не динамическое хранилище.
Если мусор становится проблемой, программист на Лиспе может просто использовать эти статические техники.

*   Lisp системы велики и оставляют мало места для других программ.
Большинство Lisp систем спроектированы как законченные среды, в которых программист выполняет всю разработку и выполнение программ.
Для такого рода операций имеет смысл иметь большой язык, такой как Common Lisp, с огромным набором инструментов.
Однако становится все более распространенным использование Лиспа как одного компонента в вычислительной среде, которая может включать UNIX, X Windows, emacs, и другие взаимодействующие программы.
В такой гетерогенной среде было бы полезно иметь возможность определять и запускать небольшие Lisp процессы, которые не включают мегабайты неиспользуемых инструментов.
Некоторые последние компиляторы поддерживают эту опцию, но пока она не распространена.

*   Lisp - сложный язык высокого уровня, и программисту может быть сложно предвидеть затраты на различные операции.
В общем, проблема не в том, что эффективное кодирование невозможно, а втом, что трудно достичь этого эффективного кодирования.
На таком языке как Си, опытный программист имеет довольно хорошее представление о том, как каждый оператор будет компилироваться в инструкции на языке ассемблера. 
Но в Лиспе очень похожие операторы могут компилироваться в очень разные инструкции ассемблерного уровня, в зависимости от тонкого взаимодействия между данными объявлениями(declarations) и возможностями компилятора.
[На Стр. 318](B9780080571157500108.xhtml#p318) приведен пример, в котором добавление объявления ускоряет выполнение тривиальной функци в  40 раз.
Не эксперты не понимают, когда такие деклараци необходимы, и расстраиваются из-за их кажущихся несоответствий.
Опытный программист на Лиспе со временем вырабатывает хорошую "модель эфффективности" и необходимость таких деклараций становится очевидной.
Последние компиляторы, такие как CMU's Python, обеспечивают обратную связь, которая облегчает процесс обучения этому.

Таким образом, Lisp позволяет писать программы в самых разнообразных стилях, некоторые эффективные, некоторые не очень.
Программист, который пишет Лисп-программы в том же стиле, что и программы на Си, вероятно обнаружит, что Лисп имеет сопоставимую скорость, возможно немного чуть медленне.
Программист, который использует некоторые из наиболее динамичных функций Лисп, обычно находит, что гораздо проще разработать работающую программу.
Затем, если результирующая программа недостаточно эффективна у вас будет больше времени, чтобы вернуться назад и улучшить критические разделы.
Решение о том, какие части программы используют больше всего ресурсов, принимается вызвав *инструментарий*.
Безрассудно пытаться повысить эффективность программы, предварительно не проверив, действительно ли улучшение будет иметь значение.

Одним из путей повышения эффективности является использование прототипов на Лиспе в качестве спецификации и повторная реализация этой спецификации на языке более низкого уровня, таком как Си или Си++.
Некоторые коммерческие поставщики ИИ идут по этому пути.
Альтернативой является использование Лиспа в качестве языка как для прототипа, так и для окончательной реализации.
Добавляя объявления и внося незначительные изменения в исходную программу, можно получить Лисп программу, аналогичную по эффективности программе на языке Си.

Существует четыре общих и независимых от языка метода ускорения работы алгоритма:

*   *Кеширование* результатов вычислений для повторного использования.

*   *Компиляция*, чтобы во время выполнения выполнялось меньше работы.

*   *Отсрочка/delaying* вычисления части результатов, которые могут никогда не понадобиться.

*   *Индексирование* структуры данных для более быстрого поиска.

В этой главе по порядку рассматривается каждый из четырех методов
Затем мы вернемся к важной проблеме  *инструментария*.
Глава завершается обучающим случаем программы упрощения.
Описанные здесь методы позволяют ускорить выполнение этой программы в 130-раз.

[Глава 10](B9780080571157500108.xhtml) концентрируется на "уловках/tricks" для дальнейшего повышения эффективности.

## 9.1 Кеширование результатов предыдущих вычислений: Memoization(запоминание)

Начнем с простой математической функции, чтобы продемонстрировать преимущества методов кэширования.
Позже мы продемонстрируем более сложные примеры.

Последовательность Фибоначи определяется как числа 1,1,2,3,5,8,... где каждое число - это сумма двух предыдущих чисел.
Самая простая функция для вычисления n-го числа в этой последовательности выглядит следующим образом:

```lisp
(defun fib (n)
```

    `"Compute the nth number in the Fibonacci sequence."`

  `(if (<= n 1) 1`

      `(+ (fib (- n 1)) (fib (- n 2)))))`

Проблема этой функции в том, что она вычисляет одно и то же снова и снова.
Вычисление (`fib 5`) означает вычисление (`fib 4`) и (`fib 3`), но (`fib 4`) также требует (`fib 3`), и они оба требуют (`fib 2`), и т.д.
Есть способы переписать функцию, чтобы она делала меньше вычислений, но было бы не плохо написать функцию как есть, но чтобы она автоматически избегала избыточных вычислений?
Удивительно, но есть способ сделать именно это.
Идея состоит в том, чтобы использовать функцию `fib` для создания новой функции, которая запоминает ранее вычисленные результаты и использует их, а не пересчитывает заново.
Этот процесс называется *memoization*(придание функции памяти).
Функция `memo` это функция высшего порядка, которая принимает функцию в качестве входных данных и возвращает новую функцию, которая будет вычислять те же результаты, но не выполнять одно и тоже вычисление дважды.

```lisp
(defun memo (fn &key (key #'first) (test #'eql) name)
  "Return a memo-function of fn."
  (let ((table (make-hash-table :test test)))
    (setf (get name 'memo) table)
    #'(lambda (&rest args)
        (let ((k (funcall key args)))
          (multiple-value-bind (val found-p)
              (gethash k table)
            (if found-p val
                (setf (gethash k table) (apply fn args))))))))
```

Выражение (`memo #'fib`) создает функцию, которая запоминает свои результаты между вызовами, так что, например, если мы дважды применим её к  3, первый вызов выполнит вычисление (`fib 3`), но второй будет просто будет искать результат в хеш-таблице.
После трассировки `fib`, это будет выглядеть так:

```lisp
> (setf memo-fib (memo #'fib)) => #  <  CLOSURE -  67300731  >
> (funcall memo-fib 3) =>
(1 ENTER FIB: 3)
```

    `(2 ENTER FIB: 2)`

          `(3 ENTER FIB: 1)`

          `(3 EXIT FIB: 1)`

          `(3 ENTER FIB: 0)`

          `(3 EXIT FIB: 1)`

    `(2 EXIT FIB: 2)`

    `(2 ENTER FIB: 1)`

    `(2 EXIT FIB: 1)`

```lisp
(1 EXIT FIB: 3)
3
> (funcall memo-fib 3) =  >  3
```

Во второй раз, когда мы вызываем `memo-fib` с аргументом 3, ответ просто извлекается, а не вычислялется заново.
Но проблема в том, что во время вычисления (`fib 3`), мы по прежнему вычисляем (`fib 2`) несколько раз.
Было бы лучше, если бы даже внутренние рекурсивные вызовы были запомнены(memoized), но это были вызовы неизменённого fib,а не `memo-fib`.
Эту проблему легко решить с помощью функции `memoize`:

```lisp
(defun memoize (fn-name &key (key #'first) (test #'eql))
  "Replace fn-name's global definition with a memoized version."
  (clear-memoize fn-name)
```

При передаче символа, который именует функцию, `memoize` изменяет глобальное определение функции на memo-функцию.
Таким образом, любые рекурсивные вызовы сначала будут обращаться к  memo-функции, а не к исходной функции.
Это как раз то, что мы хотим.
Далее мы сопоставим запоминающие(memoized) и не запоминающие(unmemoized) версии `fib`.
Первый вызов (`fib 5`) с трассировкой `fib`:

```lisp
> (fib 5) =>
(1 ENTER FIB: 5)
```

      `(2 ENTER FIB: 4)`

            `(3 ENTER FIB: 3)`

                  `(4 ENTER FIB: 2)`

                          `(5 ENTER FIB: 1)`

                          `(5 EXIT FIB: 1)`

                          `(5 ENTER FIB: 0)`

                          `(5 EXIT FIB: 1)`

                  `(4 EXIT FIB: 2)`

                  `(4 ENTER FIB: 1)`

                  `(4 EXIT FIB: 1)`

            `(3 EXIT FIB: 3)`

            `(3 ENTER FIB: 2)`

                  `(4 ENTER FIB: 1)`

                  `(4 EXIT FIB: 1)`

                  `(4 ENTER FIB: 0)`

                  `(4 EXIT FIB: 1)`

            `(3 EXIT FIB: 2)`

      `(2 EXIT FIB: 5)`

      `(2 ENTER FIB: 3)`

            `(3 ENTER FIB: 2)`

                  `(4 ENTER FIB: 1)`

                  `(4 EXIT FIB: 1)`

                  `(4 ENTER FIB: 0)`

                  `(4 EXIT FIB: 1)`

            `(3 EXIT FIB: 2)`

            `(3 ENTER FIB: 1)`

            `(3 EXIT FIB: 1)`

      `(2 EXIT FIB: 3)`

```lisp
(1 EXIT FIB: 8)
8
```

Мы видим, что (`fib 5`) и (`fib 4`) вычисляются один раз, но (`fib 3`) вычисляется дважды, (`fib 2`) трижды, а (`fib 1`) пять раз.
Ниже мы вызываем (`memoize 'fib`) и повторяем вычисление.
На этот раз, каждое вычисление выполняется только один раз.
Кроме того, когда вычисление (`fib 5`) повторяется, ответ возвращается немедленно без промежуточных вычислений, и при следующем вызове (`fib 6`) может быть использовано значение (`fib 5`).

```lisp
> (memoize 'fib) => #  <  CLOSURE 76626607  >
> (fib 5) =>
(1 ENTER FIB: 5)
```

    `(2 ENTER FIB: 4)`

          `(3 ENTER FIB: 3)`

                `(4 ENTER FIB: 2)`

                      `(5 ENTER FIB: 1)`

                      `(5 EXIT FIB: 1)`

                      `(5 ENTER FIB: 0)`

                      `(5 EXIT FIB: 1)`

                `(4 EXIT FIB: 2)`

          `(3 EXIT FIB: 3)`

    `(2 EXIT FIB: 5)`

```lisp
(1 EXIT FIB: 8)
8
> (fib 5)   =>  8
> (fib 6) =>
(1 ENTER FIB: 6)
(1 EXIT FIB: 13)
13
```

Понимание того, почему это работает, требует четкого понимания различий между функциями и именами функций.
Исходная форма (`defun fib ...`) выполняет две задачи: создает функцию и и сохраняет ее как значение (`symbol-function`) символа-функции `fib`.
Внутри этой функции есть две ссылки на `fib`; они компилируются (или интерпретируются) как инструкции для получения  `symbol-function` для `fib` и применения её к аргументу.

`memoize` извлекает исходную функцию и преобразует её с помощью `memo` в функцию, которая при вызове, сначала просматривает таблицу, чтобы узнать, известен ли уже ответ.
Если нет, вызывается исходная функция, и в таблицу помещается новое значение.
Хитрость в том, что `memoize` берет эту новую функцию и делает её значением символа-фукнции(`symbol-function`) имени функции.
Это означает, что все ссылки в исходной функции теперь перейдут на новую функцию, и таблица будет правильно проверяться при каждом рекурсивном вызове.
Еще одна сложность для `memo:` функция `gethash` возвращает два значения, найденное в таблице и индикатор того, присутствует ключ или нет.
Мы используем `multiple-value-bind` для захвата обоих значений, чтобы мы могли отличить случай, когда `nil` является значением функции сохраненным в таблице, от случая, когда сохраненного значения нет.

Если вы вносите изменения в функцию преобразованную memoize, вам необходимо перекомпилировать исходное определение, а затем повторить вызов memoize.
При разработке вашей программы, вместо того, чтобы сказать `(memoize 'f)`, было бы проще заключить соответствующее определение в форму `memoize` следующим образом:

```lisp
(memoize
```

    `(defun f (x) ...)`

    `)`

Или определить макрос, который объединяет `defun` и `memoize`:

```lisp
(defmacro defun-memo (fn args &body body)
  "Define a memoized function."
  `(memoize (defun ,fn ,args . ,body)))

(defun-memo f (x) ...)
```

Оба этих подхода основаны на том факте, что  `defun` возвращает имя определенной функции.

| []() |             |            |          |                |
|------|-------------|------------|----------|----------------|
| *n*  | `(fib *n*)` | unmemoized | memoized | memoized up to |
| 25   | 121393      | 1.1        | .010     | 0              |
| 26   | 196418      | 1.8        | .001     | 25             |
| 27   | 317811      | 2.9        | .001     | 26             |
| 28   | 514229      | 4.7        | .001     | 27             |
| 29   | 832040      | 8.2        | .001     | 28             |
| 30   | 1346269     | 12.4       | .001     | 29             |
| 31   | 2178309     | 20.1       | .001     | 30             |
| 32   | 3524578     | 32.4       | .001     | 31             |
| 33   | 5702887     | 52.5       | .001     | 32             |
| 34   | 9227465     | 81.5       | .001     | 33             |
| 50   | 2.0e10      | -          | .014     | 34             |
| 100  | 5.7e20      | -          | .031     | 50             |
| 200  | 4.5e41      | -          | .096     | 100            |
| 500  | 2.2e104     | -          | .270     | 200            |
| 1000 | 7.0e208     | -          | .596     | 500            |
| 1000 | 7.0e208     | -          | .001     | 1000           |
| 1000 | 7.0e208     | -          | .876     | 0              |

Теперь мы показываем таблицу, в которой указаны значения `(fib *n*)` для определенного *n*, и время в секундах для вычисления значения, до и после выполнения `(memoize 'fib)`.
Для дальнейших значений *n*, показаны приближенные значения в таблице, хотя на самом деле `fib` возвращает точное целое число.
Для незапоминающей(unmemoized) версии, я остановился на *n*  =  34, потому что время выполнения становилось слишком длинным.
Для замоминающей(memoized) версии, даже  *n*  =  1000 заняло меньше секунды.

Обратите внимание, что есть три записи для (`fib 1000`).
Первая запись представляет собой инкрементное вычисление, когда таблица содержит запомненные(memoized) значения до 500, вторая запись показывает время поиска в таблице, когда (`fib 1000`) уже вычислено, а третья - время для полного вычисления, начиная с пустой таблицы.

Следует отметить, что есть два общих подхода к обсуждению эффективности алгоритма.
Один из них - сопоставить алгоритм с репрезентативными входными данными, как мы сделали в этой таблице.
Другой - анализировать *асимптотическую сложность* алгоритма.
Для задачи `fib` асимптотический анализ рассматривает, сколько времени требуется для вычисления `(fib *n*)` когда *n* приближается к бесконечности.
Обозначение *O*(*f*(*n*)) используется для описания сложности.
Например, запоминающая версия `fib` является алгоритмом *O*(*n*), потому что время вычислений ограничено некоторым постоянным временем *n*, для любого значения *n*.
Незапоминающая версия, оно оказывается, is *O*(1.7*n*), что означает, что вычисление `fib` для n  +  1 может занимать в 1.7 раза больше времени, чем вычисление `fib` для *n*.
Проще говоря, запоминающая версия имеет *линейную* сложность, в то время как не запоминающая версия имеет *экспотенциальную* сложность.
[В упражнении 9.4](B9780080571157500091.xhtml#p4655) ([Page 308](B9780080571157500091.xhtml#p308)) объясняется откуда взялось 1.7, и дается более жесткая оценка сложности.

Представленная выше версия `memo` негибка по нескольким причинам.
Во-первых, она работает только с функцией с одним аргументом.
Во-вторых, она возвращает сохраненное значение только для аргументов, которые являются `eql`, потому что именно так работают хеш-таблицы по умолчанию. 
Для некоторых приложений мы хотим получить сохраненное значение для аргументов, которые являются `equal`.
В-третьих, нет возможности удалять записи в хеш-таблице.
Во многих приложениях бывают случаи, когда было бы хорошо очистить хеш-таблицу либо потому, что она стала слишком большой, либо потому, что мы закончили некий набор связаных проблем и переходим к новой проблеме.

Приведенные ниже версии `memo` и `memoize` решают эти три проблемы.
Они совместимы с предыдущей версией, но добавляют три новых ключевых слова для расширений.
Ключевое слово `name` сохраняет хеш-таблицу в списке свойств этого имени, поэтому к ней можно получить доступ с помощью `clear-memoize`.
Ключевое слово `test` сообщает какую хэш-таблицу создавать: `eq, eql или equal`.
Наконец, ключевое слово `key` сообщает, какие аргументы функции нужно индексировать.
По умолчанию, используется первый аргумент (для совместимости с предыдущей версией), но можно использовать любую комбинацию аргументов.
Если вы хотите использовать все аргументы, укажите в качестве ключа `identity`.
Обратите внимание: если key(ключ) представляет собой список аргументов, вам придется использовать хэш-таблицы сравнивающие через `equal`.

```lisp
(defun memo (fn &key (key #'first) (test #'eql) name)
  "Return a memo-function of fn."
  (let ((table (make-hash-table :test test)))
    (setf (get name 'memo) table)
    #'(lambda (&rest args)
        (let ((k (funcall key args)))
          (multiple-value-bind (val found-p)
              (gethash k table)
            (if found-p val
                (setf (gethash k table) (apply fn args))))))))
```

```lisp
(defun memoize (fn-name &key (key #'first) (test #'eql))
  "Replace fn-name's global definition with a memoized version."
  (clear-memoize fn-name)
  (setf (symbol-function fn-name)
        (memo (symbol-function fn-name)
              :name fn-name :key key :test test)))
```

```lisp
(defun clear-memoize (fn-name)
  "Clear the hash table from a memo function."
  (let ((table (get fn-name 'memo)))
    (when table (clrhash table))))
```

## 9.2 Компиляция одного языка в другой

В [Главе 2](B9780080571157500029.xhtml) мы определили новый язык - язык граматических правил,- который обрабатывался интерпретатором, разработанным специально для этого языка.
*Интепретатор/interpreter* это программа, котора смотрит на некоторую структуру данных, представляющую "программу" или последовательность правил определенного типа, и интерпретирует или вычисляет(оценивает) эти правила.
В этом отличие от *компилятора/compiler*,  который переводит некоторый набор правил на одном языке в программу на другом языке.

Функция `generate` была интерпретатором для языка "language" определенного набором граматических правил.
Интерпретация этих правил проста, но процесс несколько неэффективен, так как  generate должен постоянно искать в граматике `*grammar*` подходящее правило, затем подсчитывать длину правой части и так далее.

Компилятор для этого языка правил принимает каждое правило и переводит его в функцию.
Эти функции могут затем вызывать друг друга без необходимости поиска в граматике `*grammar*`.
Мы реализуем этот подход с помощью функции `compile-rule`.
Она использует вспомогательные функции `one-of` и `rule-lhs` и `rule-rhs` со [Страницы 40](B9780080571157500029.xhtml#p40), повторенные здесь:

```lisp
(defun rule-lhs (rule)
```

  `"The left-hand side of a rule."`

  `(first rule))`

```lisp
(defun rule-rhs (rule)
```

  `"The right-hand side of a rule."`

  `(rest (rest rule)))`

```lisp
(defun one-of (set)
```

  `"Pick one element of set, and make a list of it."`

  `(list (random-elt set)))`

```lisp
(defun random-elt (seq)
  "Pick a random element out of a sequence."
  (elt seq (random (length seq))))
```

Функция `compile-rule` превращает правило в определение функции, создавая код на Лиспе, который реализует все действия, которые будут выполняться при интерпретации правила.
Есть три случая.
Если каждый элемент правой части является атомом, то правило является лексическим правилом, которое компилируется в вызов `one-of` для случайного выбора слова.
Если есть только один элемент с правой стороны, то вызывается `build-code` для генерации кода для него.
Обычно это будет вызов (append)добавления для создания списка.
Наконец, если в правой части есть несколько элементов, каждый из них превращается в код с помощью `build-code`; присваиваются числовые значения(номера) с помощью `build-case`; а затем строится оператор `case` для выбора одного из случаев.

```lisp
(defun compile-rule (rule)
```

  `"Translate a grammar rule into a LISP function definition."`

  `(let ((rhs (rule-rhs rule)))`

      `'(defun ,(rule-lhs rule) ()`

```lisp
        ,(cond ((every #'atom rhs) '(one-of ',rhs))
```

              `((length  =l rhs) (build-code (first rhs)))`

              `(t '(case (random .(length rhs))`

                  `,@(build-cases 0 rhs)))))))`

```lisp
(defun build-cases (number choices)
```

  `"Return a list of case-clauses"`

  `(when choices`

      `(cons (list number (build-code (first choices)))`

              `(build-cases (+ number 1) (rest choices)))))`

```lisp
(defun build-code (choice)
```

  `"Append together multiple constituents"`

  `(cond ((null choice) nil)`

              `((atom choice) (list choice))`

              `((length=1 choice) choice)`

              `(t '(append ,@(mapcar #'build-code choice)))))`

```lisp
(defun length=1 (x)
  "Is x a list of length 1?"
  (and (consp x) (null (cdr x))))
```

Код Лиспа, созданный с помощью `compile-rule`(компиляции правил), должен быть скомпилирован или интерпретирован, чтобы сделать его доступным для системы Лисп.
Мы можем сделать это с помощью одной из следующих форм.
Обычно мы хотели бы вызвать `compile`, но во время отладки может быть проще этого не делать.

```lisp
(dolist (rule *grammar*) (eval (compile-rule rule)))
(dolist (rule *grammar*) (compile (eval (compile-rule rule))))
```

Одним из частых способов использования компиляции является определение макроса, который расширяется в код, созданный компилятором.
Таким образом, мы просто вводим вызовы макроса и не должны беспокоиться о том, чтобы убедиться, что все последние правила скомпилированы.
Мы можем реализовать это следующим образом:

```lisp
(defmacro defrule (&rest rule)
```

    `"Define a grammar rule"`

    `(compile-rule rule))`

```lisp
(defrule Sentence -> (NP VP))
(defrule NP -> (Art Noun))
(defrule VP -> (Verb NP))
(defrule Art -> the a)
(defrule Noun -> man bail woman table)
(defrule Verb -> hit took saw liked)
```

Фактически, выбор использования одного большого списка правил (например, `*grammar*`) по сравнению с использованием отдельных макросов для определения правил не зависит от выбора: компилятор или интерпретатор.
Мы могли бы так же легко определить defrule, просто поместив правило в граматику - `*grammar*`.
Такие макросы, как defrule, полезны, когда вы хотите определить правила в разных местах, возможно, в нескольких отдельных файлах.
Метод `defparameter` подходит, когда все правила могут быть определены в одном месте.

Мы можем увидеть код Лисп, сгенерированный `compile-rule` двумя способами: передав ему правило напрямую:

```lisp
> (compile-rule '(Sentence -> (NP VP)))
(DEFUN SENTENCE ()
```

      `(APPEND (NP) (VP)))`

```lisp
> (compile-rule '(Noun -> man bail woman table))
(DEFUN NOUN ()
```

      `(ONE-OF '(MAN BALL WOMAN TABLE)))`

или макрорасширением выражения defrule.
Компилятор был разработан для создания того же кода, который мы писали при первом подходе к проблеме генерации (см. [Страница 35](B9780080571157500029.xhtml#p35)).

```lisp
> (macroexpand '(defrule Adj* -> () Adj (Adj Adj*)))
(DEFUN ADJ* ()
```

  `(CASE (RANDOM 3)`

      `(0 NIL)`

      `(1 (ADJ))`

      `(2 (APPEND (ADJ) (ADJ*)))))`

Интерпретаторы обычно легче писать, чем компиляторы, хотя в этом случае даже компилятор не будет слишком сложным.
Интерпретаторы также по своей сути более гибкие, чем компиляторы, потому что они откладывают принятие решений до последнего возможного момента.
Например, наш компилятор считает правую часть правила списком слов, даже если каждый элемент является атомом.
Во всех остальных случаях элементы рассматриваются как нетерминальные.
Это могло вызвать проблемы, если бы мы расширили определение `Noun`(Существительного), включив в него составное существительное(noun) "chow chow":

```lisp
(defrule Noun -> man ball woman table (chow chow))
```

Правило расширилось бы до следующего кода:

```lisp
(DEFUN NOUN ()
  (CASE (RANDOM 5)
```

      `(0 (MAN))`

      `(1 (BALL))`

      `(2 (WOMAN))`

      `(3 (TABLE))`

      `(4 (APPEND (CHOW) (CHOW)))))`

Проблема в том, что `man`, `ball` и все остальные неожиданно стали рассматриваться как функции, а не как буквальные слова.
Таким образом, мы получим ошибку времени выполнения, сообщающую нам о неопределенных функциях.
Эквивалентное правило не вызовет проблем для интерпретатора, который ждет, пока ему действительно не понадобиться сгенерировать символ, чтобы решить, является ли он словом или нетерминальным символом.
Таким образом, семантика правил различна для интерпретатора и компилятора, и мы, разработчики программ, должны быть очень осторожны с тем, как мы указываем фактическое значение правила.
Фактически, это, вероятно, было ошибкой в ​​версии интерпретатора, поскольку он эффективно запрещает таким словам, как "noun" и "sentence" встречаться в виде слов, если они также являются названиями категорий.
Одно из возможных решений конфликта - сказать, что элемент правой части представляет слово, если это атом, и список категорий, если это список.
Если бы мы действительно остановились на этом соглашении, то мы могли бы модифицировать и интерпретатор, и компилятор, чтобы соответствовать этому соглашению.
Другая возможность - представить слова в виде строк, а категории в виде символов.

Обратной стороной потери гибкости во время выполнения является получение диагностики во время компиляции.
Например, оказывается, что в системе Common Lisp, которую я использую сейчас, я получаю несколько полезных сообщений об ошибках, когда пытаюсь скомпилировать ошибочную версию `Noun`:

```lisp
> (defrule Noun -> man bail woman table (chow chow))
The following functions were referenced but don't seem defined:
```

  `CHOW referenced by NOUN`

  `TABLE referenced by NOUN`

  `WOMAN referenced by NOUN`

  `BALL referenced by NOUN`

  `MAN referenced by NOUN`

```lisp
NOUN
```

Еще одна проблема с описанной здесь схемой компиляции - это возможность *конфликтов имен*.
В схеме интерпретации использовались только имена функции generate и переменной `*grammar*`.
При компиляции каждая левая часть правила становится именем функции.
Автор грамматики должен убедиться, что он или она не использует имя существующей функции Лиспа, и, следовательно, не переопределяет ее.
Хуже того, если одновременно разрабатывается более одной грамматики, у них не должно быть общих функций.
Если это произойдет, пользователю придется выполнять перекомпиляцию при каждом переключении с одной грамматики на другую.
Это может затруднить сравнение грамматик.
Лучшее решение этой проблемы - использовать идею *пакетов* в Common Lisp, но для небольших упражнений конфликта имен можно  избежать достаточно легко, поэтому мы не будем исследовать пакеты до [раздела 24.1](B9780080571157500248.xhtml#s0010).

Главное преимущество компилятора - это скорость выполнения, когда это имеет значение.
Для идентичных грамматик, выполняемых в одной конкретной реализации Common Lisp на одной машине, наш интерпретатор генерирует около 75 предложений в секунду, в то время как компилируемый подход дает около 200.
Таким образом, это более чем в два раза быстрее, но разница незначительна, если нам не нужно генерировать многие тысячи предложений.
В [разделе 9.6] (# s0035) мы увидим другой компилятор с еще большим ускорением.

Необходимость оптимизации кода, создаваемого вашими макросами и компиляторами, в конечном итоге зависит от качества базового Лисп компилятора.
Например, рассмотрим следующий код:

```lisp
(defun f1 (n l)
      (let ((l1 (first l))
                  (l2 (second l)))
```

                `(expt (* 1 (+ n 0))`

              `(- 4 (length (list l1 l2))))))`

```lisp
F1
> (defun f2 (n l) (* n n)) =>F2
> (disassemble 'fl)
```

| []()       |             |
|------------|-------------|
| `6 PUSH`   | `ARGIO ; N` |
| `7 MOVEM`  | `PDL-PUSH`  |
| `8 *`      | `PDL-POP`   |
| `9 RETURN` | `PDL-POP`   |

```lisp
Fl
> (disassemble 'f2)
```

| []()       |            |
|------------|------------|
| `6 PUSH`   | `ARGO ; N` |
| `7 MOVEM`  | `PDL-PUSH` |
| `8 *`      | `PDL-POP`  |
| `9 RETURN` | `PDL-POP`  |

```lisp
F2
```

Этот Лисп компилятор генерирует точно такой же код для `f1` и `f2`.
Обе функции возводят аргумент `n` в квадрат, и четыре машинные инструкции говорят: "Возьмите 0-й аргумент, сделайте его копию, умножьте эти два числа и верните результат". Понятно, что компилятор имеет некоторые знания об основных функциях Лиспа.
В случае с `f1` он был достаточно умен, чтобы избавиться от локальных переменных `l1` и `l2` (и их инициализации), а также от вызовов `first, second, length` и `list` и большей части арифметики.
Компилятор может сделать это, потому что он знает о функциях `length` и `list` и арифметических функциях.
Некоторые из этих знаний могут быть в форме правил упрощения.

Как пользователю этого компилятора, мне нет необходимости писать умные макросы или компиляторы, которые генерируют упрощенный код, как показано в `f2`; Я могу слепо сгенерировать код с возможной неэффективностью, как в `f1`, и предполагать, что Лисп компилятор скроет мою лень.
С другим компилятором, который не знает о таких оптимизациях, мне пришлось бы быть более осторожным с генерируемым мной кодом.

## 9.3 Отложенные Вычисления

Вернувшись на [Страницу 45](B9780080571157500029.xhtml#p45), мы увидим программу для генерации всех строк, полученных из грамматики.
Одним из недостатков этой программы было то, что некоторые грамматики производили бесконечное количество строк, поэтому программа не завершалась при использовании этих грамматик.

Оказывается, мы часто хотим иметь дело с бесконечными множествами.
Конечно, мы не можем перечислить все элементы бесконечного множества, но мы должны иметь возможность представлять множество и выбирать элементы по одному.
Другими словами, мы хотим иметь возможность указывать, как создается множество(набор) (или другой объект), но задерживать фактическое построение, возможно, делая это постепенно с течением времени.
Это звучит как работа для замыканий: мы можем указать конструктор множества как функцию, а затем вызвать функцию через некоторое время.
Мы реализуем этот подход с синтаксисом, используемым в Scheme - макрос `delay` создает замыкание, которое будет вычислено позже, а функция `force` вызывает эту функцию и кэширует значение.
Для этого мы используем структуры типа `delay`.
В структуре задержки(delay) есть два поля: value(значение) и function(функция).
Первоначально поле value не определено, а поле function(функции) содержит замыкание, которое будет вычислять значение.
Вначале delay применяется в force, где вызывается function, и ее результат сохраняется в поле значения.
Затем поле function устанавливается в nil, чтобы указать, что нет необходимости вызывать функцию снова.
Функция `force` проверяет, нужно ли вызывать функцию, и возвращает значение.
Если `force` передается аргумент, который не является delay, она просто возвращает аргумент.

```lisp
(defstruct delay value (computed? nil))

(defmacro delay (&rest body)
  "A computation that can be executed later by FORCE."
  `(make-delay :value #'(lambda () . ,body)))
```

```lisp
(defun force (x)
```

  `"Find the value of x, by computing if it is a delay."`

  `(if (not (delay-p x))`

            `x`

            `(progn`

            `(when (delay-function x)`

                  `(setf (delay-value x)`

                          `(funcall (delay-function x)))`

                  `(setf (delay-function x) nil))`

            `(delay-value x))))`
```

Вот пример использования `delay`.
Список `x` строится с использованием комбинации нормального вычисления и отложенного вычисления.
Таким образом, `1` печатается при создании `x`, а `2` - нет:

```lisp
(setf x (list (print 1) (delay (print 2)))) =>
1
(1 #S(DELAY .-FUNCTION (LAMBDA () (PRINT 2))))
```

Второй элемент вычисляется (и печатается), когда он вызывается force.
Но затем повторение force  просто извлекает кешированное значение, а не вызывает функцию снова:

```lisp
> (force (second x)) =>
2
2
> x => (1 #S(DELAY : VALUE 2))
> (force (second x)) => 2
```

Теперь посмотрим, как можно использовать delay(задержки) для построения бесконечных множеств.
Бесконечное множество будет считаться частным случаем того, что мы будем называть *pipe*: список с вычисленным компонентом `first` и компонентом `rest`, который является либо обычным списком, либо отложенным(delayed) значением.
Каналы(pipes) также называются отложенными списками, генерированными списками и (чаще всего) потоками.
Мы будем использовать термин *pipe*, потому что *stream* уже имеет значение в Common Lisp.
В книге *Программирование искусственного интеллекта* ([Чарняк и др.
1987](B9780080571157500285.xhtml#bb0180)) также называет эти структуры pipes, резервируя streams(потоки) для отложенных структур, которые не кэшируют вычисленные результаты.

Чтобы отличать pipes(каналы) от списков, мы будем использовать функции доступа(аксессоры) `head` и `tail` вместо `first` и `rest`.
Мы также будем использовать `empty-pipe` вместо `nil`, `make-pipe` вместо `cons` и `pipe-elt` вместо `elt`.
Обратите внимание, что `make-pipe` - это макрос, который задерживает вычисление хвоста(tail).

```lisp
(defmacro make-pipe (head tail)
```

  `"Create a pipe by evaluating head and delaying tail."`

  `'(cons ,head (delay ,tail)))`

```lisp
(defconstant empty-pipe nil)
(defun head (pipe) (first pipe))
(defun tail (pipe)(force (rest pipe)))
(defun pipe-elt (pipe i)
```

  `"The i-th element of a pipe, 0-based"`

  `(if (= i 0)`

      `(head pipe)`

      `(pipe-elt (tail pipe) (- i 1))))`

Вот функция, которую можно использовать для создания большой или бесконечной последовательности целых чисел с отложенным вычислением:

```lisp
(defun integers (&optional (start 0) end)
```

  `"A pipe of integers from START to END.`

  `If END is nil, this is an infinite pipe."`

  `(if (or (null end) (<= start end))`

      `(make-pipe start (integers (+ start 1) end))`

      `nil))`

А вот и пример её использования.
pipe `c` представляет числа от 0 до бесконечности.
При его создании вычисляется только нулевой элемент, 0.
Вычисление других элементов задерживается(delayed).

```lisp
> (setf c (integers 0)) => (0 . #S(DELAY :FUNCTION #  <  CLOSURE -  77435477  >))
>  (pipe-elt c 0) =>    0
```

Вызов `pipe-elt` для просмотра третьего элемента приводит к вычислению элементов с первого по третий.
Числа от 0 до 3 кэшируются в правильных позициях, а другие элементы остаются невычисленными.
Другой вызов `pipe-elt` с большим индексом заставит их вычислить отложенную функцию.

```lisp
> (pipe-elt c 3) => 3
c =>
(0 . #S(DELAY
```

                `: VALUE`

                `(1 . #S(DELAY`

                                    `: VALUE`

                                    `(2 . #S(DELAY`

                                                    `: VALUE`

                                                    `(3 . #S(DELAY`

                                                                      `:FUNCTION`

                                                                      `#  <  CLOSURE -  77432724  >))))))))`

Хотя это, кажется, работает нормально, но придется заплатить высокую цену.
Каждое отложенное значение должно храниться в двухэлементной структуре, где одним из элементов является замыкание.
Таким образом, часть памяти теряется.
Так же некоторое время теряется, так как `tail` или `pipe-elt` должны проходить по структуре.

Альтернативное представление для pipe - это пары (*value . closure*), где значения замыкания сохраняются в фактических cons-ячейках по мере их вычисления.
Раньше нам требовались структуры типа delay, чтобы отличать отложенный(задержанный) от неотложенного объекта, но в pipe, как мы знаем, rest может быть только одним из трех: nil, список или отложенное значение.
Таким образом, мы можем использовать замыкания напрямую вместо использования структур `delay`, если у нас есть способ отличить замыкания от списков.
Скомпилированные замыкания - это атомы, поэтому их всегда можно отличить от списков.
Но иногда замыкания реализуются в виде списков, начинающихся с `lambda` или какого-либо другого символа, зависящего от реализации. [2](#fn0015) Встроенная функция `functionp` определена как истинная для таких списков, а также для всех символов и всех объектов, возвращаемых `compile`.
Но использование `functionp` означает, что у нас не может быть pipe, который включает в себя символ `lambda` как элемент, потому что его можно спутать с замыканием:

```lisp
> (functionp (last '(theta iota kappa lambda))) => T
```

Если мы будем последовательно использовать скомпилированные функции, то мы сможем устранить проблему с тестированием используя встроенный предикат `compiled-function-p`.
Следующие определения не делают этого предположения:

```lisp
(defmacro make-pipe (head tail)
```

  `"Create a pipe by evaluating head and delaying tail."`

  `'(cons ,head #'(lambda () ,tail)))`

```lisp
(defun tail (pipe)
```

  `"Return tail of pipe or list, and destructively update`

  `the tail if it is a function."`

  `(if (functionp (rest pipe))`

      `(setf (rest pipe) (funcall (rest pipe)))`

      `(rest pipe)))`

Все остальное остается прежним.
Если мы перекомпилируем `integers` (потому что она использует макрос `make-pipe`), мы увидим следующее поведение.
Во-первых, создание бесконечного pipe `c` аналогично:

```lisp
> (setf c (integers 0)) => (0 . #  <  CLOSURE 77350123  >)
> (pipe-elt c 0) => 0
```

Доступ к принудительному вычислению элемента pipe для всех промежуточных элементов, и, как и прежде, оставляет без вычисления последующие элементы:

```lisp
> (pipe-elt c 5) => 5
> c => (0 1 2 3 4 5 . #  <  CLOSURE 77351636  >)
```

Pipes также могут использоваться для конечных списков.
Здесь мы видим pipe длиной 11:

```lisp
> (setf i (integers 0 10)) => (0 . #  <  CLOSURE 77375357  >)
> (pipe-elt i 10) => 10
> (pipe-elt i 11) => NIL
> i => (0 1 2 3 4 5 6 7 8 9 10)
```

Понятно, что эта версия тратит меньше места и гораздо аккуратнее убирает после себя.
Фактически, полностью вычисленный pipe превращается в список!
Эта эффективность была достигнута за счет общего принципа разработки программ.
Обычно мы стремимся построить более сложные абстракции, например каналы(pipes), из более простых, например задержек/отложенных вычислений(delays).
Но в этом случае часть функциональных возможностей, которые обеспечивали отложенные вычисления, была дублирована cons-ячейками, составляющими каналы(pipes), поэтому более эффективная реализация каналов вообще не использует задержки.

Вот еще несколько служебных функций для каналов(pipes):

```lisp
(defun enumerate (pipe &key count key (result pipe))
```

  `"Go through all (or count) elements of pipe,`

  `possibly applying the KEY function.
(Try PRINT.)"`

  `;; Returns RESULT, which defaults to the pipe itself.`

  `(if (or (eq pipe empty-pipe) (eql count 0))`

              `result`

              `(progn`

              `(unless (null key) (funcall key (head pipe)))`

              `(enumerate (tail pipe) :count (if count (- count 1))`

                                                `: key key : result result))))`

```lisp
(defun filter (pred pipe)
```

  `"Keep only items in pipe satisfying pred."`

  `(if (funcall pred (head pipe))`

      `(make-pipe (head pipe)`

                                          `(filter pred (tail pipe)))`

      `(filter pred (tail pipe))))`

А вот и применение pipes: генерация простых чисел с использованием алгоритма решета Эратосфена:

```lisp
(defun sieve (pipe)
```

  `(make-pipe (head pipe)`

              `(filter #'(lambda (x) (/= (mod x (head pipe)) 0))`

                                `(sieve (tail pipe)))))`

```lisp
(defvar *primes* (sieve (integers 2)))
> *primes* => (2 . #  <  CLOSURE 3075345  >)
> (enumerate *primes* :count 10) =>
(2 3 5 7 11 13 17 19 23 29 31 . #  <  CLOSURE 5224472  >)
```

Наконец, вернемся к проблеме генерации всех строк в грамматике.
Для начала нам понадобятся еще несколько служебных функций:

```lisp
(defun map-pipe (fn pipe)
```

  `"Map fn over pipe, delaying all but the first fn call."`

  `(if (eq pipe empty-pipe)`

            `empty-pipe`

            `(make-pipe (funcall fn (head pipe))`

                            `(map-pipe fn (tail pipe)))))`

```lisp
(defun append-pipes (x y)
```

  `"Return a pipe that appends the elements of x and y."`

  `(if (eq x empty-pipe)`

              `y`

              `(make-pipe (head x)`

                                    `(append-pipes (tail x) y))))`

```lisp
(defun mappend-pipe (fn pipe)
```

  `"Lazily map fn over pipe, appending results."`

  `(if (eq pipe empty-pipe)`

                    `empty-pipe`

                    `(let ((x (funcall fn (head pipe))))`

                        `(make-pipe (head x)`

                                        `(append-pipes (tail x)`

                                                                `(mappend-pipe`

                                                                                        `fn (tail pipe)))))))`

Теперь мы можем переписать `generate-all` и `combine-all`, чтобы использовать каналы(pipes) вместо списков.

Все остальное такое же, как на [Странице 45](B9780080571157500029.xhtml#p45).

```lisp
(defun generate-all (phrase)
```

  `"Generate a random sentence or phrase"`

  `(if (listp phrase)`

      `(if (null phrase)`

              `(list nil)`

              `(combine-all-pipes`

                    `(generate-all (first phrase))`

                    `(generate-all (rest phrase))))`

      `(let ((choices (rule-rhs (assoc phrase *grammar*))))`

        `(if choices`

                    `(mappend-pipe #'generate-all choices)`

                    `(list (list phrase))))))`

```lisp
(defun combine-all-pipes (xpipe ypipe)
```

  `"Return a pipe of pipes formed by appending a y to an x"`

  `;; In other words, form the cartesian product.`

  `(mappend-pipe`

      `#'(lambda (y)`

                  `(map-pipe #'(lambda (x) (append-pipes x y))`

                                                    `xpipe))`

      `ypipe))`

С этими определениями, вот pipe всех предложений из `*grammar2*` (из [Страница 43](B9780080571157500029.xhtml#p43)):

```lisp
> (setf ss (generate-all 'sentence)) =>
((THE . #  <  CLOSURE 27265720  >) . #  <  CLOSURE 27266035>)
> (enumerate ss :count 5) =>
((THE . #  <  CLOSURE 27265720  >)
(A . #  <  CLOSURE 27273143  >)
(THE . #  <  CLOSURE 27402545  >)
(A . #  <  CLOSURE 27404344  >)
(THE . #  <  CLOSURE 27404527  >)
(A . #  <  CLOSURE 27405473  >) . #  <  CLOSURE 27405600  >)
> (enumerate ss .-count 5 :key #'enumerate) =>
((THE MAN HIT THE MAN)
(A MAN HIT THE MAN)
(THE BIG MAN HIT THE MAN)
(A BIG MAN HIT THE MAN)
(THE LITTLE MAN HIT THE MAN)
(THE . #  <  CLOSURE 27423236  >) . #  <  CLOSURE 27423343  >)
> (enumerate (pipe-elt ss 200)) =>
(THE ADIABATIC GREEN BLUE MAN HIT THE MAN)
```

Хотя мы смогли представить бесконечный набор предложений и перечислить их экземпляры, мы все еще не решили все проблемы.
Во-первых, это перечисление никогда не дойдет до предложения, в котором нет глагольной фразы "hit the man"(ударить человека).
Мы будем видеть все более длинные списки прилагательных, но никаких других изменений.
Другая проблема заключается в том, что леворекурсивные правила по-прежнему будут вызывать бесконечные циклы.
Например, если расширение для `Adj*` было `(Adj* -> (Adj* Adj) ())` вместо `(Adj* -> () (Adj Adj*))`, то перечисление никогда не будет завершаться, потому что pipes должны генерировать первый элемент.

Мы использовали задержки(delays) и каналы(pipes) для двух основных целей: чтобы отложить на потом вычисления, которые могут вообще не понадобиться, и для получения явного представления больших или бесконечных множеств.
Следует отметить, что язык Prolog имеет иное решение первой проблемы (но не второй).
Как мы увидим в [главе 11](B978008057115750011X.xhtml), Prolog генерирует решения по одному, автоматически отслеживая возможные точки возврата.
Там, где pipes позволяют нам представлять бесконечное количество альтернатив в данных, Prolog позволяет нам представлять эти альтернативы в самой программе.

**Exercise  9.1 [h]** Когда дана функция `f` и канал `p`, `mappend-pipe` возвращает новый канал, который в конечном итоге перечислит все `(f (first p))`, затем все `(f (second p))` и так далее.
Это считается "неправильным", если `(f (first p))` имеет бесконечное количество элементов.
Определите функцию, которая будет правильно чередовать элементы, чтобы все они в конечном итоге были перечислены.
Покажите, что функция работает, изменив `generate-all` для работы с ней.

## 9.4 Индексирование данных

Lisp упрощает использование списков в качестве универсальной структуры данных.
Список может представлять множество или упорядоченную последовательность, а список с подсписками может представлять дерево или граф.
Для быстрого прототипирования зачастую проще всего представить данные в виде списков, но для эффективности это не всегда лучшая идея.
Чтобы найти элемент в списке длиной *n*, потребуется в среднем *n*/2 шагов.
Это верно для простого списка, списка ассоциаций(alist) или списка свойств(plist).
Если *n* может быть большим, стоит рассмотреть другие структуры данных, такие как хеш-таблицы, векторы, списки свойств и деревья.

Выбор правильной структуры данных и алгоритма так же важен в Лиспе, как и в любом другом языке программирования.
Несмотря на то, что Lisp предлагает широкий спектр структур данных, часто стоит потратить некоторые усилия на построение правильной структуры данных для часто используемых данных.
Например, хеш-таблицы Lisp слишком обобщены и поэтому могут быть неэффективными.
Вы можете создавать свои собственные хеш-таблицы, если, например, вам никогда не нужно удалять элементы, что делает открытое хеширование привлекательной возможностью.
Мы увидим пример эффективного индексирования в [раздел 9.6](#s0035)([Страница 297] (B9780080571157500091.xhtml#p297)).

## 9.5 Инструментарий: Позволяющий решить, что оптимизировать

Поскольку Lisp - очень хороший язык для быстрого создания прототипов, мы можем рассчитывать быстро получить работающую реализацию.
Прежде чем мы приступим к попыткам повысить эффективность реализации, неплохо посмотреть, какие части используются чаще всего.
Улучшение малоиспользуемых функций - пустая трата времени.

Минимальная поддержка, которая нам нужна, - это подсчет количества вызовов выбранных функций, а затем распечатка итогов.
Это называется *профилированием* функций. [3](# fn0020) Для каждой функции, подлежащей профилированию, мы меняем определение так, чтобы оно увеличивало счетчик, а затем вызывала исходную функцию.

Большинство систем на Лиспе имеют встроенный механизм профилирования.
Если в вашей системе он есть, обязательно используйте его.
Код в этом разделе предназначен для тех, у кого нет такой возможности, и является примером того, как можно управлять функциями.
Ниже приводится простое средство профилирования.
Для каждой профилируемой функции он ведет подсчет количества ее вызовов в свойстве `profile-count` имени функции.

```lisp
(defun profile1 (fn-name)
```

  `"Make the function count how often it is called"`

  `;; First save away the old, unprofiled function`

  `;; Then make the name be a new function that increments`

  `;; a counter and then calls the original function`

    `(let ((fn (symbol-function fn-name)))`

          `(setf (get fn-name 'unprofiled-fn) fn)`

      `(setf (get fn-name 'profile-count) 0)`

      `(setf (symbol-function fn-name)`

                `(profiled-fn fn-name fn))`

      `fn-name))`

```lisp
(defun unprofile1 (fn-name)
```

  `"Make the function stop counting how often it is called."`

  `(setf (symbol-function fn-name) (get fn-name 'unprofiled-fn))`

  `fn-name)`

```lisp
(defun profiled-fn (fn-name fn)
```

  `"Return a function that increments the count."`

  `#'(lambda (&rest args)`

      `(incf (get fn-name 'profile-count))`

      `(apply fn args)))`

```lisp
(defun profile-count (fn-name) (get fn-name 'profile-count))
```

  `(defun profile-report (fn-names &optional (key #'profile-count))`

  `"Report profiling statistics on given functions."`

              `(loop for name in (sort fn-names #'> :key key) do`

```lisp
                    (format t "~&  ~  7D  ~  A" (profile-count name) name)))
```

Это все, что нам нужно для базовой функциональности.
Однако есть несколько способов улучшить это.
Во-первых, было бы неплохо иметь макросы, такие как `trace` и `untrace`, которые позволяют пользователю одновременно профилировать несколько функций и отслеживать то, что было профилировано.
Во-вторых, может быть полезно видеть время, затраченное на каждую функцию, а также количество вызовов.

Кроме того, важно избегать двойного профилирования функции, поскольку это удвоит количество зарегистрированных вызовов, не предупреждая пользователя о каких-либо проблемах.
Допустим, мы ввели следующую последовательность команд:

```lisp
(defun f (x) (g x))
(profile1 'f)
(profile1 'f)
```

Тогда определение `f` будет примерно таким:

```lisp
(lambda (&rest args)
```

      `(incf (get 'f 'profile-count))`

      `(apply #'(lambda (&rest args)`

            `(incf (get 'f 'profile-count))`

            `(apply #'(lambda (x) (g x))`

                        `args))`

                `args))`

В результате любой вызов `f` в конечном итоге вызовет исходный `f`, но только после двукратного увеличения счетчика.

Еще одно соображение: что происходит, когда профилируемая функция переопределяется пользователем.
Единственный способ гарантировать, что переопределенная функция продолжит профилирование, - это изменить определение макроса defun для поиска функций, которые следует профилировать.
Изменение системных функций, таких как defun, - рискованная перспектива, и в *Common Lisp the Language*, 2-е издание, это явно запрещено.
Вместо этого мы сделаем следующее: убедимся, что следующий вызов `profile` повторно профилирует любые функции, которые были переопределены.
Мы делаем это, отслеживая как исходную непрофилированную функцию, так и профилированную функцию.
Мы также храним список всех профилируемых функций.

Кроме того, мы посчитаем время, потраченное на каждую функцию.
Однако пользователя предупреждают, что нельзя слишком доверять цифрам времени.
Во-первых, они включают накладные расходы на средство профилирования.
Это может быть значительным, особенно потому, что средство conses(конструирует списки) и, таким образом, может вызвать сборку мусора, которая в противном случае не была бы выполнена.
Во-вторых, разрешения системных часов может быть недостаточно для точного отсчета времени.
Для функций, которые занимают около 1/10 секунды или более, цифры будут надежными, но для быстрых функций это не так.

Вот основной код для `profile` и `unprofile:`

```lisp
(defvar *profiled-functions* nil
```

  `"Function names that are currently profiled")`

```lisp
(defmacro profile (&rest fn-names)
```

  `"Profile fn-names.
With no args, list profiled functions."`

  `'(mapcar #'profile1`

              `(setf *profiled-functions*`

            `(union *profiled-functions* fn-names))))`

```lisp
(defmacro unprofile (&rest fn-names)
```

  `"Stop profiling fn-names.
With no args, stop all profiling."`

  `'(progn`

      `(mapcar #'unprofile1`

                  `,(if fn-names fn-names '*profiled-functions*))`

      `(setf *profiled-functions*`

                  `,(if (null fn-names)`

            `nil`

                  `'(set-difference *profiled-functions*`

                        `',fn-names)))))`

Идиома ' ',`fn-names` заслуживает комментария, так как она обычна, но поначалу может сбивать с толку.
Её может быть легче понять, если написать в эквивалентной форме '`(quote ,fn-names)`.
Как всегда, обратная кавычка создает структуру как с постоянными, так и с вычисляемыми компонентами.
В этом случае `quote` постоянна, а переменная `fn-names` вычисляется.
В MacLisp для этой цели была определена функция `kwote`:

```lisp
(defun kwote (x) (list 'quote x))
```

Теперь нам нужно изменить `profile1` и `unprofile1`, чтобы выполнить дополнительный учет: Для `profile1` есть два случая.
Если пользователь дважды подряд выполняет `profile1` для одного и того же имени функции, то во второй раз мы заметим, что текущая функция совпадает с функцией, хранящейся в свойстве `profiled-fn`, поэтому больше ничего не нужно должно быть сделано.
В противном случае мы создаем профилированную функцию, сохраняем ее как текущее определение имени в свойстве `profiled-fn`, сохраняем непрофилированную функцию и инициализируем счетчики.

```lisp
(defun profile1 (fn-name)
```

  `"Make the function count how often it is called"`

  `;; First save away the old, unprofiled function`

  `;; Then make the name be a new function that increments`

  `;; a counter and then calls the original function`

  `(let ((fn (symbol-function fn-name)))`

      `(unless (eq fn (get fn-name 'profiled-fn))`

              `(let ((new-fn (profiled-fn fn-name fn)))`

                  `(setf (symbol-function fn-name) new-fn`

                              `(get fn-name 'profiled-fn) new-fn`

                              `(get fn-name 'unprofiled-fn) fn`

                              `(get fn-name 'profile-time) 0`

                              `(get fn-name 'profile-count) 0))))`

        `fn-name)`

```lisp
(defun unprofile1 (fn-name)
```

  `"Make the function stop counting how often it is called."`

  `(setf (get fn-name 'profile-time) 0)`

  `(setf (get fn-name 'profile-count) 0)`

  `(when (eq (symbol-function fn-name) (get fn-name 'profiled-fn))`

      `;; normal case: restore unprofiled version`

      `(setf (symbol-function fn-name)`

                `(get fn-name 'unprofiled-fn)))`

  `fn-name)`

Теперь рассмотрим вопрос о времени.
Существует встроенная функция Common Lisp, `get-internal-real-time`, которая возвращает время, прошедшее с начала сеанса Lisp.
Поскольку оно может быстро стать большим числом, некоторые реализации предоставляют другую функцию подсчета времени, которая идет по кругу, а не увеличивается постоянно, но которая может иметь более высокое разрешение, чем `get-internal-real-time`.
Например, на машинах TI Explorer Lisp, `get-internal-real-time` измеряет интервалы в 1/60 секунды, а `time:microsecond-time` измеряет интервалы в 1/1000000 секунд, но возвращаемое значение возвращается к нулю. каждый час или около того.
Функция `time:microsecond-time-difference` используется для сравнения двух из этих чисел с компенсацией зацикливания, если произошло не более одного зацикливания.

В приведенном ниже коде я использую условные символы макроса чтения `#+` и `#-`, чтобы определить правильное поведение как на машинах Explorer, так и на других машинах.
Мы видели, что `#` - это специальный символьный знак для reader, который выполняет разные действия в зависимости от последующего символьного знака.
Например, `#'fn` читается как `(function fn)`.
Последовательность знаков `#+` определена так, что `#+`*feature expression* читается как *expression*, если *feature*(функциональность) определена в текущей реализации, и как ничто, если это не так.
Последовательность `#-` действует прямо противоположно.
Например, в TI Explorer мы получим следующее:

```lisp
>'(hi #+TI t #+Symbolics s #-Explorer e #-Mac m) => (HI T M)
```

Условные знаки макроса чтения используются в следующих определениях:

```lisp
(defun get-fast-time ()
```

  `"Return the elapsed time.
This may wrap around;`

  `use FAST-TIME-DIFFERENCE to compare."`

  `#+Explorer (time:microsecond-time) ; do this on an Explorer`

  `#-Explorer (get-internal-real-time)) ; do this on a non-Explorer`

```lisp
(defun fast-time-difference (end start)
```

  `"Subtract two time points."`

  `#+Explorer (time:microsecond-time-difference end start)`

  `#-Explorer (- end start))`

```lisp
(defun fast-time->seconds (time)
```

  `"Convert a fast-time interval into seconds."`

  `#+Explorer (/ time 1000000.0)`

  `#-Explorer (/ time internal-time-units-per-second))`

Следующим шагом является обновление `profiled-fn` для отслеживания данных о времени.
Самый простой способ сделать это - установить для переменной, скажем, `start`, время, когда происходит вход в функцию, запустить функцию и затем увеличить время выполнения функции на разницу между текущим временем и `start`.
Проблема с этим подходом состоит в том, что каждая функция в стеке вызовов получает значение для времени каждой вызываемой функции.
Предположим, что функция `f` рекурсивно вызывает себя пять раз, причем каждый вызов и возврат происходят с интервалом в секунду, так что все вычисления занимают девять секунд.
Тогда с `f` будет начислено девять секунд за внешний вызов, семь секунд за следующий и так далее, всего 25 секунд, хотя на самом деле на все они вместе потребовалось всего девять секунд.

Лучшим алгоритмом было бы заряжать каждую функцию только на время, прошедшее с момента последнего вызова или возврата.
Тогда `f` будет заряжаться только девять секунд.
Переменная `*profile-call-stack*` используется для хранения стека пар: имя функции/время входа.
Этот стек управляется `profile-enter` и `profile-exit`, чтобы получить правильные тайминги.

Функции, которые используются при каждом вызове профилируемой функции, объявляются `inline`.
В большинстве случаев 
вызов функции компилируется в машинные инструкции, которые устанавливают список аргументов и переходят к местоположению определения функции.
При использовании встроенной функции тело функции компилируется в строке в месте вызова функции.
Таким образом, нет дополнительных затрат на настройку списка аргументов и переход к определению.
Объявление `inline` может появляться везде, где может появиться любое другое объявление.
В этом случае функция `proclaim` используется для регистрации глобального объявления.
Inline объявления более подробно обсуждаются на [Страница 317](B9780080571157500108.xhtml#p317).

```lisp
(proclaim '(inline profile-enter profile-exit inc-profile-time))
(defun profiled-fn (fn-name fn)
```

  `"Return a function that increments the count, and times."`

  `#'(lambda (&rest args)`

          `(profile-enter fn-name)`

          `(multiple-value-progl`

                `(apply fn args)`

                `(profile-exit fn-name))))`

```lisp
(defvar *profile-call-stack* nil)
(defun profile-enter (fn-name)
```

  `(incf (get fn-name 'profile-count))`

  `(unless (null *profile-call-stack*)`

      `;; Time charged against the calling function:`

      `(inc-profile-time (first *profile-call-stack*)`

                              `(car (first *profile-call-stack*))))`

  `;; Put a new entry on the stack`

  `(push (cons fn-name (get-fast-time))`

              `*profile-call-stack*))`

```lisp
(defun profile-exit (fn-name)
```

  `;; Time charged against the current function:`

  `(inc-profile-time (pop *profile-call-stack*)`

                                          `fn-name)`

  `;; Change the top entry to reflect current time`

  `(unless (null *profile-call-stack*)`

      `(setf (cdr (first *profile-call-stack*))`

              `(get-fast-time))))`

```lisp
(defun inc-profile-time (entry fn-name)
```

  `(incf (get fn-name 'profile-time)`

                        `(fast-time-difference (get-fast-time) (cdr entry))))`

Наконец, нам нужно обновить `profile-report`, чтобы печатать временные данные, а также счетчики.
Обратите внимание, что по умолчанию `fn-names` является копией глобального списка.
Это потому, что мы передаем `fn-names` в `sort`, которая является разрушающей функцией.
Мы не хотим, чтобы глобальный список изменялся в результате этой сортировки.

```lisp
(defun profile-report (&optional
                                            (fn-names (copy-list *profiled-functions*))
                                            (key #'profile-count))
    "Report profiling statistics on given functions."
    (let ((total-time (reduce #'  +  (mapcar #'profile-time fn-names))))
        (unless (null key)
            (setf fn-names (sort fn-names #'> :key key)))
        (format t "~&Total elapsed time: ~d seconds."
                        (fast-time-> seconds total-time))
        (format t Count Secs Time% Name")
        (loop for name in fn-names do
                  (format t "~&~7D ~6,2F ~3d% ~A"
                                (profile-count name)
                                (fast-time-> seconds (profile-time name))
                                (round (/ (profile-time name) total-time) .01)
                                name))))
(defun profile-time (fn-name) (get fn-name 'profile-time))
```

Эти функции можно использовать, вызвав `profile`, затем выполнив некоторые типичные вычисления, затем вызвав `profile-report` и, наконец, `unprofile`.
Может быть удобно предоставить один макрос для выполнения всех этих действий одновременно:

```lisp
(defmacro with-profiling (fn-names &rest body)
  '(progn
        (unprofile . ,fn-names)
        (profile . ,fn-names)
        (setf *profile-call-stack* nil)
        (unwind-protect
                (progn . ,body)
            (profile-report ',fn-names)
            (unprofile . ,fn-names))))
```

Обратите внимание на использование функции `unwind-protect` для создания отчета и вызова `unprofile`, даже если вычисление было прервано.
`unwind-protect` - это особая форма, которая принимает любое количество аргументов.
Она  вычисляет первый аргумент и, если все идет хорошо, вычисляет остальные аргументы и возвращает результат первого, как и `progl`.
Но если во время вычисления первого аргумента возникает ошибка и вычисление прерывается, то последующие аргументы (называемые формами очистки) все равно вычисляются.

## 9.6 Пример исследования эффективности: программа SIMPLIFY

Предположим, мы хотим ускорить выполнение программы `simplify` из [главы 8](B978008057115750008X.xhtml).
В этом разделе показано, как сочетание общих методов - запоминания(memoizing), индексации и компиляции - может использоваться для ускорения программы в 130 раз.
[Глава 15](B9780080571157500157.xhtml) покажет другой подход: заменить алгоритм совершенно другим.

Первым шагом к более быстрой программе является определение *эталонного теста*(benchmark), набора тестов, представляющего типичную рабочую нагрузку.
Ниже приводится краткий список тестовых задач (и их ответов), которые типичны для задачи `simplify`.

```lisp
(defvar *test-data* (mapcar #'infix-> prefix
  '((d (a * x ^ 2  +  b * x  +  c) / d x)
      (d ((a * x ^ 2  +  b * x  +  c) / x) / d x)
      (d((a*x ^ 3  +  b * x ^ 2  +  c * x  +  d)/x ^ 5)/dx)
      ((sin (x  +  x)) * (sin (2 * x))  +  (cos (d (x ^ 2) / d x)) ^ 1)
      (d (3 * x  +  (cos x) / x) / d x))))
(defvar *answers* (mapcar #'simplify *test-data*))
```

Функция `test-it` просматривает тестовые данные, проверяя правильность каждого ответа и при необходимости распечатывая данные профилирования.

```lisp
(defun test-it (&optional (with-profiling t))
```

`    "Time a test run.
and make sure the answers are correct."`

```lisp
    (let ((answers
                  (if with-profiling
                          (with-profiling (simplify simplify-exp pat-match
                                                            match-variable variable-p)
                              (mapcar #'simplify *test-data*))
                          (time (mapcar #'simplify *test-data*)))))
        (mapc #'assert-equal answers *answers*)
        t))
(defun assert-equal (x y)
    "If x is not equal to y, complain."
    (assert (equal x y) (x y)
                    "Expected ~a to be equal to ~a" x y))
```

Вот результаты (`test-it`) с профилированием и без него:

```lisp
> (test-it nil)
Evaluation of (MAPCAR #'SIMPLIFY *TEST-DATA*) took 6.612  seconds.
> (test-it t)
Total elapsed time: 22.819614  seconds
```

| []()    |         |         |                  |
|---------|---------|---------|------------------|
| `Count` | `Secs`  | `Time%` | `Name`           |
| `51690` | `11.57` | `51%`   | `PAT-MATCH`      |
| `37908` | `8.75`  | `38%`   | `VARIABLE-P`     |
| `1393`  | `0.32`  | `1%`    | `MATCH-VARIABLE` |
| `906`   | `0.20`  | `1%`    | `SIMPLIFY`       |
| `274`   | `1.98`  | `9%`    | `SIMPLIFY-EXP`   |

Обычно выполнение теста занимает 6,6 секунды, хотя время увеличивается втрое при добавлении дополнительных затрат на профилирование.
Должно быть ясно, что для ускорения работы мы должны либо ускорить, либо сократить количество обращений к `pat-match` или `variable-p`, поскольку вместе они составляют 89% вызовов (и 89% времени тоже).
Мы рассмотрим три метода достижения обеих этих целей.

#### Memoization(Запоминание вычисленных результатов)

Рассмотрим правило, которое преобразует (`x + x`) в (`2 * x`).
Как только это будет сделано, мы должны упростить результат, что предполагает повторное упрощение компонентов.
Если бы `x` был некоторым сложным выражением, это могло бы занять много времени и, безусловно, будет расточительным, потому что `x` уже упрощен и не может измениться.
Мы уже сталкивались с подобными проблемами раньше, и решением является мемоизация: заставьте `simplify` запоминать проделанную работу, а не повторять ее.
Можно просто сказать:

```lisp
(memoize 'simplify :test #'equal)
```

Неясны два вопроса: какую хеш-таблицу использовать и нужно ли очищать хеш-таблицу между проблемами.
Упрощение рассчитывалось для всех четырех комбинаций хэш-таблиц `eq` или `equal` и сброса или отсутствия сброса между задачами.
Самым быстрым результатом было `equal` хеширование без сброса(очистки).
Обратите внимание, что с хешированием `eq` версия с сбросом была быстрее, предположительно потому, что она не могла использовать преимущества общих подвыражений между примерами (поскольку они не являются `eq`).

| hashing | resetting | time |
|---------|-----------|------|
| none    | -         | 6.6  |
| equal   | yes       | 3.8  |
| equal   | no        | 3.0  |
| eq      | yes       | 7.0  |
| eq      | no        | 10.2 |

Такой подход заставляет функцию `simplify` запоминать выполненную работу в хэш-таблице.
Если накладные расходы на обслуживание хеш-таблицы становятся слишком большими, есть альтернатива: заставить данные помнить, что было сделано упрощением.
Этот подход был использован в MACSYMA: она представляет операторы в виде списков, а не атомов.
Таким образом, вместо `(* 2 x)` MACSYMA будет использовать `((*) 2 x)`.
Функция упрощения будет разрушающим образом вставлять маркер в список операторов.
Таким образом, результатом упрощения 2 *x* будет `((* simp) 2 x)`.
Затем, когда упрощатель будет вызваться рекурсивно для этого выражения, он заметит маркер `simp` и вернет выражение как есть.

Идея связать мемоизационную информацию с данными, а не с функцией будет более эффективной, если не будет много функций, которые все захотят поставить свои отметки на одни и те же данные.
Подход, ориентированный на данные, имеет два недостатка: он не идентифицирует структуры, которые `equal`, но не `eq`, и, поскольку он требует явного изменения данных, он требует, чтобы каждая другая операция, которая манипулирует данными, знала о маркере.
Прелесть подхода с использованием хеш-таблицы в том, что он прозрачен; никакой код не должен знать, что происходит мемоизация.

#### Индексация

В настоящее время мы просматриваем весь список правил по одному, проверяя каждое правило.
Это неэффективно, потому что большинство правил можно тривиально исключить, если только они были правильно проиндексированы.
Самая простая схема индексации - это иметь отдельный список правил, индексируемых под каждым оператором.
Вместо того, чтобы проверять `simplify-exp` каждый член `*simplification-rules*` с помощью `simpleify-exp`, он может просматривать только меньший список правил для соответствующего оператора.
Вот как:

```lisp
(defun simplify-exp (exp)
```

`    "Simplify using a rule.
or by doing arithmetic.`

```lisp
    or by using the simp function supplied for this operator.
    This version indexes simplification rules under the operator."
    (cond ((simplify-by-fn exp))
                ((rule-based-translator exp (rules-for (exp-op exp)) ;***
                      :rule-if #'exp-lhs :rule-then #'exp-rhs
                      :action #'(lambda (bindings response)
                                            (simplify (sublis bindings response)))))
                ((evaluable exp) (eval exp))
                (t exp)))
(defvar *rules-for* (make-hash-table :test #'eq))
(defun main-op (rule) (exp-op (exp-lhs rule)))
(defun index-rules (rules)
    "Index all the rules under the main op."
    (clrhash *rules-for*)
    (dolist (rule rules)
        ;; nconc instead of push to preserve the order of rules
        (setf (gethash (main-op rule) *rules-for*)
                    (nconc (gethash (main-op rule) *rules-for*)
                                  (list rule)))))
(defun rules-for (op) (gethash op *rules-for*))
(index-rules *simplification-rules*)
```

Время для мемоизированной(memoized) и индексированной(indexed) версии дает нам 0,98 секунды, по сравнению с 6,6 секунды для исходного кода и 3 секунд для мемоизированного(memoized) кода.
Если бы это не помогло, мы могли бы рассмотреть более сложные схемы индексации.
Вместо этого мы переходим к рассмотрению других средств повышения эффективности.

**Exercise  9.2 [m]** Список правил для каждого оператора хранится в хеш-таблице с оператором в качестве ключа.
Альтернативой могло бы быть хранение правил в списке свойств каждого оператора, предполагая, что операторы должны быть символами.
Реализуйте эту альтернативу и сопоставьте ее с подходом с хэш-таблицей.
Помните, что вам нужен какой-то способ очистки старых правил - тривиальный с помощью хеш-таблицы, но не автоматический со списками свойств.

#### Компиляция

Вы можете посмотреть на `simpleify-exp` как на интерпретатор языка правил упрощения.
Один из проверенных методов повышения эффективности - замена интерпретатора компилятором.
Например, правило `(x + x = 2 * x)` может быть скомпилировано во что-то вроде:

```lisp
(lambda (exp)
    (if (and (eq (exp-op exp) '+) (equal (exp-lhs exp) (exp-rhs exp)))
            (make-exp :op '* :lhs 2 :rhs (exp-rhs exp))))
```

Это устраняет необходимость в использовании конструирования списков(консинга/consing) и передаче привязок переменных и должно быть быстрее, чем обычная процедура сопоставления.
При использовании вместе с индексированием отдельные правила могут быть проще, потому что мы уже знаем, что у нас есть правильный оператор.
Например, с указанным выше правилом, обозначенным знаком "+", теперь его можно скомпилировать как:

```lisp
(lambda (exp)
    (if (equal (exp-lhs exp) (exp-rhs exp))
            (make-exp :op '* :lhs 2 :rhs (exp-lhs exp))))
```

Важно отметить, что когда эти функции возвращают nil, это означает, что они не смогли упростить выражение, и мы должны рассмотреть другие способы упрощения.

Другая возможность состоит в том, чтобы скомпилировать набор правил одновременно, чтобы индексирование фактически было частью скомпилированного кода.
В качестве примера я показываю здесь небольшой набор правил и возможную компиляцию набора правил.
Созданная функция предполагает, что `x` не является атомом.
Это уместно, потому что мы заменяем `simpleify-exp`, а не `simplify`.
Кроме того, мы вернем nil, чтобы указать, что `x` уже упрощен.
Я выбрал немного другой формат кода; основное отличие - это возможность вводить имена переменных для подвыражений.
Это особенно полезно для глубоко вложенных шаблонов(образцов).
Другое отличие состоит в том, что я явно создаю ответ с помощью вызова `list`, а не `make-exp`.
Обычно это считается плохим стилем, но, поскольку это код, созданный компилятором, я хотел, чтобы он был максимально эффективным.
Если бы представление типа данных exp изменилось, мы могли бы просто изменить компилятор; задача гораздо проще, чем поиск всех ссылок, разбросанных по программе, написанной человеком.
Следующие комментарии не были созданы компилятором.

```lisp
(x * 1  =  x)
(1 * x  =  x)
(x * 0  =  0)
(0 * x  =  0)
(x * x  =  x ^ 2)
(lambda (x)
    (let ((xl (exp-lhs x))
                (xr (exp-rhs x)))
        (or (if (eql xr '1)        ; (x*1  =  X)
                        xl)
                (if (eql xl '1)        ; (1*x  =  X)
                        xr)
                (if (eql xr '0)        ; (x*0  =  0)
                        '0)
                (if (eql xl '0)        ; (0*x  =  0)
                        '0)
                (if (equal xr xl)    ; (x*x  =  x  ^  2)
                        (list '^ xl '2)))))
```

Я выбрал этот формат для кода, потому что я представлял (и позже *show*), что для него будет довольно легко написать компилятор.

#### Компилятор с одним правилом

Здесь я показываю полный компилятор c одним правилом, за которым следует компилятор индексированного набора правил.
Компилятор с одним правилом работает так:

```lisp
> (compile-rule '(= (+ x x) (* 2 x)))
(LAMBDA (X)
```

`    (IF (OP?
X '+)`

```lisp
        (LET ((XL (EXP-LHS X))
                    (XR (EXP-RHS X)))
          (IF (EQUAL XR XL)
                  (SIMPLIFY-EXP (LIST '* '2 XL))))))
```

Получая правило, он генерирует код, который сначала проверяет образец, а затем строит правую часть правила, если образец совпадает.
По мере того, как код генерируется, соответствия устанавливаются между переменными в образце, такими как `x`, и переменными в сгенерированном коде, например, `xl`.
Они хранятся в списке ассоциаций `*bindings*`.
Сопоставление можно разбить на четыре случая: переменные, которые НЕ были замечены ранее, переменные, которые наблюдались раньше, атомы и списки.
Например, в первый раз, когда мы сталкиваемся с `x` в приведенном выше правиле, тест не генерируется, поскольку все что угодно может соответствовать `x`.
Но запись `(x . xl)` добавляется в список `*bindings*`, чтобы отметить эквивалентность.
Когда встречается второй `x`, генерируется проверка/тест `(equal xr xl)`.

Организовать компилятор немного сложнее, потому что мы должны делать сразу три вещи: возвращать сгенерированный код, отслеживать `*привязки*` и отслеживать, что делать "дальше", то есть когда тест успешен, нам нужно сгенерировать больше кода либо для дальнейшего тестирования, либо для построения результата.
Этот код должен знать о привязках, поэтому он не может быть выполнен *до* первой части теста, но он также должен знать, где он должен быть размещен в общем коде, поэтому это было бы грязно сделать это *после* первой части теста.
Ответ - передать функцию, которая сообщит нам, какой код сгенерировать позже.
Таким образом, это делается в нужное время и тоже оказывается в нужном месте.
Такую функцию часто называют *продолжением*(*continuation*), потому что она сообщает нам, где продолжить вычисления.
В нашем компиляторе переменная `consquent` является функцией продолжения.

Компилятор называется `compile-rule`.
Он принимает правило в качестве аргумента и возвращает лямбда-выражение, реализующее правило.

```lisp
(defvar *bindings* nil
    "A list of bindings used by the rule compiler.")
(defun compile-rule (rule)
    "Compile a single rule."
    (let ((*bindings* nil))
        '(lambda (x)
            ,(compile-exp 'x (exp-lhs rule) ; x is the lambda parameter
                                        (delay (build-exp (exp-rhs rule)
                                                                                              *bindings*))))))
```

Вся работа выполняется с помощью `compile-exp`, который принимает три аргумента: переменную, которая будет представлять входные данные в сгенерированном коде, образец, которому входные данные должны быть сопоставлены, и продолжение для генерации кода, если тест пройден.
Есть пять случаев: (1) Если образец переменной в списке привязок, мы генерируем тест на равенство.
(2) Если образец представляет собой переменную, которую мы раньше не видели, то мы добавляем ее в список привязок, не генерируем никакого теста (потому что что-либо соответствует переменной), а затем генерируем соответствующий код.
(3) Если образец представляет собой атом, то совпадение будет успешным, только если ввод эквивалентен `eql` атому.
(4) Если образец является условным, например  `(?is n numberp)`, мы генерируем тест `(numberp n)`.
Другие подобные образцы могут быть включены сюда, но не были включены, поскольку они не использовались.
Наконец, (5) если образец является списком, мы проверяем, что он имеет правильный оператор и аргументы.

```lisp
(defun compile-exp (var pattern consequent)
    "Compile code that tests the expression, and does consequent
```

`    если он совпадает.
Предполагает привязки в *bindings*`

```lisp
    (cond ((get-binding pattern *bindings*)
                  ;; Test a previously bound variable
                  '(if (equal .var .(lookup pattern *bindings*))
```

  `                          ,(force consequent)))`

```lisp
                ((variable-p pattern)
                  ;; Add a new bindings; do type checking if needed.
                  (push (cons pattern var) *bindings*)
                  (force consequent))
                ((atom pattern)
                  ;; Match a literal atom
                  '(if (eql ,var '.pattern)
                            ,(force consequent)))
                ((starts-with pattern '?is)
                  (push (cons (second pattern) var) *bindings*)
                  '(if (,(third pattern) ,var)
                            ,(force consequent)))
```

`                  ;; Так.
потому что, пока что покрывается только образец ?is`

```lisp
                  ;; it is the only one used in simplification rules.
                  ;; Other patterns could be compiled by adding code here.
                  ;; Or we could switch to a data-driven approach.
                  (t ;; Check the operator and arguments
```

`                    '(if (op?
,var ',(exp-op pattern))`

```lisp
                            ,(compile-args var pattern consequent)))))
```

Функция `compile-args` используется для проверки аргументов образца.
Она генерирует форму `let`, связывающую одну или две новые переменные (для унарного или бинарного выражения), а затем вызывает `compile-exp` для генерации кода, который фактически выполняет тесты.
Она просто передает продолжение, `consquent`, в `compile-exp`.

```lisp
(defun compile-args (var pattern consequent)
    "Compile code that checks the arg or args, and does consequent
    if the arg(s) match."
    ;; First make up variable names for the arg(s).
    (let ((L (symbol var 'L))
                (R (symbol var 'R)))
        (if (exp-rhs pattern)
                ;; two arg case
                '(let ((,L (exp-lhs ,var))
                              (,R (exp-rhs ,var)))
                      ,(compile-exp L (exp-lhs pattern)
                                                  (delay
                                                      (compile-exp R (exp-rhs pattern)
                                                                                consequent))))
                ;; one arg case
                '(let ((,L (exp-lhs ,var)))
                      ,(compile-exp L (exp-lhs pattern) consequent)))))
```

Остальные функции попроще.
`build-exp` генерирует код для построения правой части `rule, op?`, проверяющий, является ли его первый аргумент выражением с заданным оператором, а `symbol` создает новый символ.
Также указан `new-symbol`, хотя он не используется в этой программе.

```lisp
(defun build-exp (exp bindings)
    "Compile code that will build the exp, given the bindings."
    (cond ((assoc exp bindings) (rest (assoc exp bindings)))
                ((variable-p exp)
                  (error "Variable  ~  a occurred on right-hand side,~
                                but not left." exp))
                ((atom exp) ",exp)
                (t (let ((new-exp (mapcar #'(lambda (x)
                                                                          (build-exp x bindings))
                                                                      exp)))
                          '(simplify-exp (list .,new-exp))))))
```

`(defun op?
(exp op)`

```lisp
    "Does the exp have the given op as its operator?"
    (and (exp-p exp) (eq (exp-op exp) op)))
(defun symbol (&rest args)
    "Concatenate symbols or strings to form an interned symbol"
    (intern (format nil "~{~a~}" args)))
(defun new-symbol (&rest args)
    "Concatenate symbols or strings to form an uninterned symbol"
    (make-symbol (format nil "~{~a~}" args)))
```

Вот несколько примеров работы компилятора:

```lisp
> (compile-rule '(= (log (^ e x)) x))
(LAMBDA (X)
```

`    (IF (OP?
X 'LOG)`

```lisp
        (LET ((XL (EXP-LHS X)))
```

`            (IF (OP?
XL '^`

```lisp
                    (LET ((XLL (EXP-LHS XL))
                                (XLR (EXP-RHS XL)))
                      (IF (EQL XLL 'E)
                                XLR))))))
> (compile-rule (simp-rule '(n * (m * x)  =  (n * m) * x)))
(LAMBDA (X)
```

`    (IF (OP?
X '*)`

```lisp
        (LET ((XL (EXP-LHS X))
                    (XR (EXP-RHS X)))
            (IF (NUMBERP XL)
```

`                    (IF (OP?
XR '*)`

```lisp
                        (LET ((XRL (EXP-LHS XR))
                                    (XRR (EXP-RHS XR)))
                            (IF (NUMBERP XRL)
                                (SIMPLIFY-EXP
                                    (LIST '*
                                                (SIMPLIFY-EXP (LIST '* XL XRL))
                                                XRR)))))))))
```

#### Компилятор с набором правил

Следующим шагом является объединение кода, сгенерированного этим компилятором одного правила, для создания более компактного кода для наборов правил.
Мы разделим полный набор правил на подмножества на основе главного оператора (как мы это делали с функцией `rules-for`) и сгенерируем по одной большой функции для каждого оператора.
Нам нужно сохранить порядок правил, поэтому возможны только определенные оптимизации, но если мы сделаем предположение, что ни одна функция не имеет побочных эффектов (безопасное предположение в этом приложении), мы все равно можем работать довольно хорошо.
Мы будем использовать средство `simp-fn`, чтобы установить одну большую функцию для каждого оператора.

Функция `compile-rule-set` принимает оператор, находит все правила для этого оператора и компилирует каждое правило индивидуально.
(Она использует `compile-indexed-rule`, а не `compile-rule`, поскольку предполагает, что мы уже выполнили индексацию для основного оператора.) После того, как каждое правило было скомпилировано, они объединяются с помощью `comb-rules`, который объединяет похожие части правил и объединяет разные части.
Результат оборачивается `лямбда`-выражением и компилируется как последняя функция упрощения для оператора.

```lisp
(defun compile-rule-set (op)
    "Compile all rules indexed under a given main op,
    and make them into the simp-fn for that op."
    (set-simp-fn op
        (compile nil
            '(lambda (x)
                ,(reduce #'combine-rules
                                  (mapcar #'compile-indexed-rule
                                                (rules-for op)))))))
(defun compile-indexed-rule (rule) .
    "Compile one rule into lambda-less code,
    assuming indexing of main op."
    (let ((*bindings* nil))
        (compile-args
            'x (exp-lhs rule)
            (delay (build-exp (exp-rhs rule) *bindings*)))))
```

Вот два примера того, что генерирует правило `compile-indexed-rule`:

```lisp
> (compile-indexed-rule '(= (log 1) 0))
  (LET ((XL (EXP-LHS X)))
    (IF (EQL XL '1)
            '0))
> (compile-indexed-rule '(= (log (^ e x)) x))
  (LET ((XL (EXP-LHS X)))
```

`    (IF (OP?
XL '^)`

```lisp
            (LET ((XLL (EXP-LHS XL))
                        (XLR (EXP-RHS XL)))
                (IF (EQL XLL 'E)
                          XLR))))
```

Следующий шаг - объединить несколько этих правил в одно.
Функция `comb-rules` берет два правила и объединяет их в максимально возможной степени.

```lisp
(defun combine-rules (a b)
    "Combine the code for two rules into one, maintaining order."
    ;; In the default case, we generate the code (or a b),
    ;; but we try to be cleverer and share common code,
    ;; on the assumption that there are no side-effects.
    (cond ((and (listp a) (listp b)
                            (= (length a) (length b) 3)
                            (equal (first a) (first b))
                            (equal (second a) (second b)))
                ;; a  =  (f x y), b  =  (f x z) =>  (f x (combine-rules y z))
                ;; This can apply when f=IF or f=LET
                (list (first a) (second a)
                            (combine-rules (third a) (third b))))
              ((matching-ifs a b)
                (if ,(second a)
                        ,(combine-rules (third a) (third b))
                        ,(combine-rules (fourth a) (fourth b))))
              ((starts-with a 'or)
                ;;    a  =  (or ... (if p y)), b  =  (if p z) =>
                ;;              (or ... (if p (combine-rules y z)))
                ;; else
                ;;    a  =  (or ...) b =  >  (or ... b)
                (if (matching-ifs (lastl a) b)
                        (append (butlast a)
                                        (list (combine-rules (lastl a) b)))
                        (append a (list b))))
```

`                (t ; ; a.
b =  >  (or a b)`

```lisp
                    '(or ,a ,b))))
(defun matching-ifs (a b)
    "Are a and b if statements with the same predicate?"
    (and (starts-with a 'if) (starts-with b 'if)
              (equal (second a) (second b))))
(defun lastl (list)
    "Return the last element (not last cons cell) of list"
    (first (last list)))
```

Вот что делает `comb-rules` с двумя сгенерированными выше правилами:

```lisp
> (combine-rules
        '(let ((xl (exp-lhs x))) (if (eql xl '1) '0))
        '(let ((xl (exp-lhs x)))
```

`              (if (op?
xl '^)`

```lisp
                      (let ((xl1 (exp-lhs xl))
                                (xlr (exp-rhs xl)))
                          (if (eql xll 'e) xlr)))))
(LET ((XL (EXP-LHS X)))
    (OR (IF (EQL XL '1) '0)
```

`            (IF (OP?
XL '^)`

```lisp
                    (LET ((XLL (EXP-LHS XL))
                                (XLR (EXP-RHS XL)))
                        (IF (EQL XLL 'E) XLR)))))
```

Теперь мы запускаем компилятор, вызывая `compile-all-rules-indexed` и показываем комбинированную скомпилированную функцию упрощения для журнала.
Комментарии были введены вручную, чтобы показать, какие правила упрощения где скомпилированы.

```lisp
(defun compile-all-rules-indexed (rules)
    "Compile a separate fn for each operator, and store it
    as the simp-fn of the operator."
    (index-rules rules)
    (let ((all-ops (delete-duplicates (mapcar #'main-op rules))))
        (mapc #'compile-rule-set ail-ops)))
> (compile-all-rules-indexed *simplification-rules*)
(SIN COS LOG  ^  * / -  +  D)
> (simp-fn 'log)
(LAMBDA (X)
    (LET ((XL (EXP-LHS X)))
        (OR (IF (EQL XL '1)
                        '0)                                        ;*log 1  =  0*
                (IF (EQL XL '0)
                        'UNDEFINED)                        ;*log 0  =  undefined*
                (IF (EQL XL 'E)
                        '1)                                        ;*log e  =  1*
```

`                (IF (OP?
XL '^)`

```lisp
                        (LET ((XLL (EXP-LHS XL))
                                    (XLR (EXP-RHS XL)))
                          (IF (EQL XLL 'E)
                                    XLR))))))              ;*log ex  =  x*
```

Если мы хотим полностью обойти упрощение, основанное на правилах, мы можем еще раз изменить `simpleify-exp`, чтобы исключить проверку правил:

```lisp
(defun simplify-exp (exp)
    "Simplify by doing arithmetic, or by using the simp function
```

`    supplied for this operator.
Do not use rules of any kind."`

```lisp
    (cond ((simplify-by-fn exp))
                ((evaluable exp) (eval exp))
                (t exp)))
```

Наконец, мы можем провести тест производительности на новом скомпилированном коде; функция `test-it` выполняется примерно за 0,15 секунды с запоминанием(memoization) и 0,05 без.
Почему мемоизация, которая помогала раньше, теперь вредит нам?
Вероятно, потому, что при доступе к хеш-таблице возникают большие накладные расходы, и эти накладные расходы окупаются только тогда, когда есть много других вычислений.

По сравнению с исходным кодом мы увидели значительное улучшение, как показано в следующей таблице.
В целом, различные улучшения эффективности привели к увеличению скорости в 130 раз - теперь мы можем сделать за минуту то, что раньше занимало два часа.
Конечно, нужно иметь в виду, что статистика хороша только для этого конкретного набора тестовых данных на этой единственной машине.
Это открытый вопрос, какую производительность вы получите на других задачах и на других машинах.

В следующей таблице приведены время выполнения и количество вызовов функций для тестовых данных:

| []()            |          |       |              |             |      |
|-----------------|----------|-------|--------------|-------------|------|
|                 | original | memo  | memo + index | memo + comp | comp |
| run time (secs) | 6.6      | 3.0   | .98          | .15         | .05  |
| speed-up        | -        | 2     | 7            | 44          | 130  |
| calls           |
| pat-match       | 51690    | 20003 | 5159         | 0           | 0    |
| variable-p      | 37908    | 14694 | 4798         | 0           | 0    |
| match-variable  | 1393     | 551   | 551          | 0           | 0    |
| simplify        | 906      | 408   | 408          | 545         | 906  |
| simplify-exp    | 274      | 118   | 118          | 118         | 274  |

## 9.7 История и ссылки

The idea of memoization was introduced by Donald Michie 1968.
He proposed using a list of values rather than a hash table, so the savings was not as great.
In mathematics, the field of dynamic programming is really just the study of how to compute values in the proper order so that partial results will already be cached away when needed.

A large part of academic computer science covers compilation; [Aho and Ullman 1972](B9780080571157500285.xhtml#bb0015) is just one example.
The technique of compiling embedded languages (such as the language of pattern-matching rules) is one that has achieved much more attention in the Lisp community than in the rest of computer science.
See [Emanuelson and Haraldsson 1980](B9780080571157500285.xhtml#bb0365), for an example.

Choosing the right data structure, indexing it properly, and defining algorithms to operate on it is another important branch of computer science; [Sedgewick 1988](B9780080571157500285.xhtml#bb1065) is one example, but there are many worthy texts.

Delaying computation by packaging it up in a `lambda` expression is an idea that goes back to Algol's use of *thunks*-a mechanism to implement call-by-name parameters, essentially by passing functions of no arguments.
The name *thunk* comes from the fact that these functions can be compiled: the system does not have to think about them at run time, because the compiler has already thunk about them.
Peter [Ingerman 1961](B9780080571157500285.xhtml#bb0570) describes thunks in detail.
[Abelson and Sussman 1985](B9780080571157500285.xhtml#bb0010) cover delays nicely.
The idea of eliminating unneeded computation is so attractive that entire languages have built around the concept of *lazy evaluation*-don't evaluate an expression until its value is needed.
See [Hughes 1985](B9780080571157500285.xhtml#bb0565) or [Field and Harrison 1988](B9780080571157500285.xhtml#bb0400).

## 9.8 Упражнения

**Упражнение 9.3 [d]** В этой главе мы представили компилятор для `simplify`.
Не намного сложнее расширить этот компилятор, чтобы он мог использовать все возможности `pat-match`.
Вместо того, чтобы смотреть только на выражения, разрешите деревья с переменными в любой позиции.
Расширить и обобщить определения compile-rule и compile-rule-set, чтобы их можно было использовать в качестве общего инструмента для любой прикладной программы, которая использует pat-match и/или rule-based-translator. .
Убедитесь, что компилятор управляется данными, чтобы программист, добавляющий новый тип шаблона в `pat-match`, также мог указать компилятору, как с ним работать.
Одна сложная часть будет учитывать сегментные переменные.
Стоит потратить немало усилий во время компиляции, чтобы сделать это эффективным во время выполнения.

**Упражнение 9.4 [m]** Определите время вычисления (fib n) без мемоизации как *Tn*.
Напишите формулу для выражения *Tn*.
Учитывая, что *T*25 & asymp; 1,1 секунды, предсказать *T*100.

**Упражнение 9.5 [m]** Рассмотрим версию игры Ним, в которую играют следующим образом: есть стопка из *n* жетонов.
Два игрока по очереди убирают жетоны из стопки; на каждом ходу игрок должен взять один, два или три жетона.
Выигрывает тот, кто берет последний жетон.
Напишите программу, которая при заданном *n* возвращает количество жетонов, которые нужно взять для обеспечения выигрыша, если это возможно.
Анализируйте время выполнения вашей программы с мемоизацией и без нее.

**Упражнение 9.6 [m]** Более сложная игра в стиле Нима известна как игра Гранди.
Игра начинается с одной стопки из * n * жетонов.
Каждый игрок должен выбрать одну стопку и разделить ее на две неравные стопки.
Первый игрок, который не может двигаться, проигрывает.
Напишите программу, чтобы играть в игру Гранди, и посмотрите, как помогает запоминание.

**Упражнение 9.7 [h]** Это упражнение описывает более сложную игру одного человека.
В этой игре игрок восемь раз бросает шестигранный кубик.
Игрок формирует четыре двузначных десятичных числа так, чтобы сумма четырех чисел была как можно больше, но не превышала 170.
Всего 171 или более баллов оцениваются как ноль.

Игра была бы детерминированной и совершенно скучной, если бы не требование, согласно которому после каждого броска игрок должен немедленно помещать цифру в столбец единиц или десятков одного из четырех чисел.

Вот образец игры.
Игрок сначала выбрасывает 3 и помещает его в столбец единиц первого числа, затем бросает 4 и помещает его в столбец десятков и так далее.
В последнем броске игрок выбрасывает 6 и в итоге получает 180.
Поскольку это значение превышает предел 170, окончательный счет игрока равен 0.

| []()     |    |    |    |    |    |    |     |    |
|----------|----|----|----|----|----|----|-----|----|
| roll     | 3  | 4  | 6  | 6  | 3  | 5  | 3   | 6  |
| lst num. | -3 | 43 | 43 | 43 | 43 | 43 | 43  | 43 |
| 2nd num. | -  | -  | -6 | -6 | 36 | 36 | 36  | 36 |
| 3rd num. | -  | -  | -  | -6 | -6 | -6 | 36  | 36 |
| 4th num. | -  | -  | -  | -  | -  | -5 | -5  | 65 |
| total    | 03 | 43 | 49 | 55 | 85 | 90 | 120 | 0  |

Напишите функцию, которая позволит вам играть в игру или серию игр.
Функция должна принимать в качестве аргумента функцию, представляющую стратегию игры.

**Упражнение 9.8 [h]** Определите хорошую стратегию игры в кости, описанной выше.
(Подсказка: моя стратегия получила в среднем 143,7 балла.)

**Упражнение 9.9 [m]** Одной из проблем, возникающих при игре в игры со случайными числами, является вероятность того, что игрок может обмануть, выяснив, что `random` будет делать дальше.
Прочтите определение функции random и опишите, как игрок может обмануть.
Затем опишите контрмеру.

**Упражнение 9.10 [м]** На [стр. 292] (B9780080571157500091.xhtml#p292) мы видели использование условных выражений времени чтения, #+ и #-, где #+ - время чтения, эквивалентное when, и #- это время чтения, эквивалентное unless.
К сожалению, не существует времени чтения эквивалентное case.
Реализуйте один.

**Упражнение 9.11 [h]** Напишите компилятор для ELIZA, который объединяет все правила сразу в одну функцию.
Насколько эффективнее скомпилированная версия?

**Упражнение 9.12 [d]** Напишите несколько правил для упрощения кода Lisp.
Некоторые из правил алгебраического упрощения будут по-прежнему действовать, но потребуются новые правила для упрощения неалгебраических функций и специальных форм.
(Поскольку `nil` является допустимым выражением в этом домене, вам придется иметь дело с проблемой полупредиката.) Вот несколько примеров правил (с использованием префиксной записи):

```lisp
(= (+ x 0) x)
(= 'nil nil) (
(= (car (cons x y)) x)
(= (cdr (cons x y)) y)
(= (if t x y) x)
(= (if nil x y) y)
(= (length nil) 0)
(= (expt y (?if x numberp)) (expt (expt y (/ x 2)) 2))
```

**Упражнение 9.13 [m]** Рассмотрим следующие две версии алгоритма решета Эратосфена.
Второй явно связывает локальную переменную.
Это того стоит?

```lisp
(defun sieve (pipe)
    (make-pipe (head pipe)
                          (filter #'(lambda (x)(/= (mod x (headpipe)) 0))
                                        (sieve (tail pipe)))))
(defun sieve (pipe)
    (let ((first-num (head pipe)))
        (make-pipe first-num
                              (filter #'(lambda (x) (/= (mod x first-num) 0))
                                            (sieve (tail pipe))))))
```

## 9.9 Ответы

**Ответ 9.4** Пусть *Fn* обозначает (`fib n`).
Тогда время для вычисления *Fn*, *Tn* будет небольшой константой для *n* &le; 1 и примерно равен *Tn-1* плюс *Tn-2* для большего *n*.
Таким образом, *Tn* примерно пропорционально *Fn*:

Tn=FnTiFi

![si1_e](images/chapter9/si1_e.gif)

Мы могли бы использовать небольшое значение *Ti* для вычисления *T*100, если бы знали *F*100.
К счастью, мы можем использовать уравнение:

Fn&alpha;&Phi;n

![si2_e](images/chapter9/si2_e.gif)

Где &phi; = (1 + &radic;(5))/2 &asymp; 1.618.
Это уравнение было выведено де Муавром в 1718 году (см. Knuth, Donald E.
*Фундаментальные алгоритмы*, стр.
78-83), но число *&phi;* имеет долгую интересную историю.
Евклид назвал это "крайним и средним соотношением", потому что отношение *A* к *B* - это отношение *A* + *B* к *A*, если *A*/*B* равно *&phi;* .
В эпоху Возрождения это называлось "божественной пропорцией", а в прошлом веке оно было известно как "золотое сечение", потому что прямоугольник со сторонами в этом соотношении можно разделить на два меньших прямоугольника, которые имеют одинаковое соотношение между стороны.
Говорят, что это приятная пропорция, когда используется в живописи и архитектуре.
Отложив историю в сторону, учитывая *T*25 &asymp; 1.1 *сек* теперь мы можем вычислить:

T100&asymp;&Phi;1001.1sec&Phi;25&asymp;5x1015sec

![si3_e](images/chapter9/si3_e.gif)

что примерно 150 миллионов лет.
Мы также можем видеть, что временные данные в таблице довольно хорошо соответствуют уравнению.
Однако можно ожидать дополнительного времени для больших чисел, потому что для добавления и сбора мусора требуется больше времени, чем для фиксированных чисел.

**Ответ 9.5** Сначала определим понятие принудительной победы.
Это происходит, когда остается три или меньше жетонов, или когда вы можете сделать ход, который принесет вашему противнику возможную потерю.
Возможная потеря - это любая позиция, не являющаяся принудительным выигрышем.
Если вы играете идеально, то возможное поражение оппонента фактически будет для вас победой, так как ничей нет.
См. Функции `win` и `loss` ниже.
Теперь ваша стратегия должна заключаться в том, чтобы выиграть игру сразу, если есть три или меньше жетонов, или иным образом выбрать наибольшее число, которое приведет к возможному проигрышу для вашего оппонента.
Если вам недоступен такой ход, возьмите только один, на том основании, что ваш противник с большей вероятностью допустит ошибку с большей стопкой, с которой нужно бороться.
Эта стратегия воплощена в функции `nim` ниже.

```lisp
(defun win (n)
    "Is a pile of n tokens a win for the player to move?"
    (or (<= n 3)
            (loss (- n 1))
            (loss (- n 2))
            (loss (- n 3))))
(defun loss (n) (not (win n)))
(defun nim (n)
    "Play Nim: a player must take 1-3; taking the last one wins.
    (con ((<= n 3) n); an immediate win
            ((loss (- n 3)) 3); an eventual win
            ((loss (- n 2)) 2); an eventual win
            ((loss (- n 1)) 1); an eventual win
            (t 1))); a loss; the 1 is arbitrary
(memoize 'loss)
```

Из этого мы можем составить таблицу времени выполнения (в секундах) с мемоизацией и без нее.
Запоминать нужно только `loss`.
(Почему?) У вас есть хорошее объяснение времени для немомизированной версии?
Что произойдет, если вы измените порядок предложений loss(потерь/проигрышей) в win и/или nim?

**Answer 9.6** We start by defining a function, `moves`, which generates all possible moves from a given position.
This is done by considering each pile of *n* tokens within a set of piles *s*.
Any pile bigger than two tokens can be split.
We take care to elimina te duplicate positions by sorting each set of piles, and then removing the duplicates.

```lisp
(defun moves (s)
    "Return a list of all possible moves in Grundy's game"
    ;; S is a list of integers giving the sizes of the piles
    (remove-duplicates
        (loop for n in s append (make-moves n s))
        :test #'equal))
(defun make-moves (n s)
    (when (>  =  n 2)
        (let ((s/n (remove n s :count 1)))
            (loop for i from 1 to (- (ceiling n 2) 1)
                        collect (sort* (list* i (-  ni) s/n)
                                                      #'>>))))
(defun sort* (seq pred &key key)
  "Sort without altering the sequence"
  (sort (copy-seq seq) pred :key key))
```

This time a loss is defined as a position from which you have no moves, or one from which your opponent can force a win no matter what you do.
A winning position is one that is not a loss, and the strategy is to pick a move that is a loss for your opponent, or if you can't, just to play anything (here we arbitrarily pick the first move generated).

```lisp
(defun loss (s)
    (let ((choices (moves s)))
        (or (null choices)
                (every #'win choices))))
(defun win (s) (not (loss s)))
(defun grundy (s)
    (let ((choices (moves s)))
        (or (find-if #'loss choices)
                (first choices))))
```

**Answer 9.7** The answer assumes that a strategy function takes four arguments: the current die roll, the score so far, the number of remaining positions in the tens column, and the number of remaining positions in the ones column.
The strategy function should return 1 or 10.

```lisp
(defun play-games (&optional (n-games 10) (player 'make-move))
```

`    "A driver for a simple dice game.
In this game the player`

`    rolls a six-sided die eight times.
The player forms four`

```lisp
    two-digit decimal numbers such that the total of the four
    numbers is as high as possible, but not higher than 170.
```

`    A total of 171 or more gets scored as zero.
After each die`

```lisp
    is rolled, the player must decide where to put it.
    This function returns the player's average score."
    (/ (loop repeat n-games summing (play-game player 0 4 4))
          (float n-games)))
(defun play-game (player &optional (total 0) (tens 4) (ones 4))
    (cond ((or (> total 170) (< tens 0) (< ones 0)) 0)
                ((and (= tens 0) (= ones 0)) total)
                (t (let ((die (roll-die)))
                        (case (funcall player die total tens ones)
                          (1 (play-game player (+ total die)
                                                      tens (- ones 1)))
                          (10 (play-game player (+ total (* 10 die))
                                                      (- tens 1) ones))
                          (t 0))))))
(defun roll-die () (+  1 (random 6)))
```

So, the expression `(play-games 5 #'make-move)` would play five games with a strategy called `make-move`.
This returns only the average score of the games; if you want to see each move as it is played, use this function:

```lisp
(defun show (player)
    "Return a player that prints out each move it makes."
    #'(lambda (die total tens ones)
            (when (= total 0) (fresh-line))
            (let ((move (funcall player die total tens ones)))
                (incf total (* die move))
                (format t "~2d-> ~  3d |  ~  @[*~]" (* move die) total (> total 170))
                  move)))
```

and call `(play-games 5 (show #'make-moves))`.

**Answer 9.9** The expression `(random 6 (make-random-state))` returns the next number that `roll-die` will return.
To guard against this, we can make `roll-die` use a random state that is not accessible through a global variable:

```lisp
(let ((state (make-random-state t)))
    (defun roll-die () (+  1 (random 6 state))))
```

**Answer 9.10** Because this has to do with read-time evaluation, it must be implemented as a macro or read macro.
Here's one way to do it:

```lisp
  (defmacro read-time-case (first-case &rest other-cases)
    "Do the first case, where normally cases are
    specified with #+ or possibly #- marks."
    (declare (ignore other-cases))
    first-case)
```

A fanciful example, resurrecting a number of obsolete Lisps, follows:

```lisp
(defun get-fast-time ()
    (read-time-case
```

| []()             |                              |
|------------------|------------------------------|
| `#+Explorer`     | `(time :microsecond-time)`   |
| `#+Franz`        | `(sys:time)`                 |
| `#+(or PSL UCI)` | `(time)`                     |
| `#+YKT`          | `(currenttime)`              |
| `#+MTS`          | `(status 39)`                |
| `#+Interlisp`    | `(clock 1)`                  |
| `#+Lispl.5`      | `(tempus-fugit)`             |
| `;; otherwise`   |                              |
|                  | `(get-internal-real-time)))` |

**Answer 9.13** Yes.
Computing (`head pipe`) may be a trivial computation, but it will be done many times.
Binding the local variable makes sure that it is only done once.
In general, things that you expect to be done multiple times should be moved out of delayed functions, while things that may not be done at all should be moved inside a delay.

----------------------

[1](#xfn0010) One could say that the FORTRAN compiler was "broken." This underscores the problem of defining the efficiency of a language-do we judge by the most popular compiler, by the best compiler available, or by the best compiler imaginable?
!!!(p) {:.ftnote1}

[2](#xfn0015) In KCL, the symbol `lambda-closure` is used, and in Allegro, it is `excl:.
lexical-closure`
!!!(p) {:.ftnote1}

[3](#xfn0020) The terms *metering* and *monitoring* are sometimes used instead of profiling.
!!!(p) {:.ftnote1}