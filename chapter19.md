# Глава 19
## Введение в естественный язык

> Язык везде.
Он проникает в наши мысли, опосредует наши отношения с другими людьми и даже проникает в наши мечты.
Подавляющая часть человеческих знаний хранится и передается на языке.
Язык настолько распространен, что мы принимаем его как должное, но без него общество, которое мы знаем, было бы невозможно.

> -Ronand Langacker

> Language and its Structure(Язык и его структура) (1967)

Естественный язык - это язык, на котором говорят люди, например английский, немецкий или тагальский.
Они противопоставляются искусственным языкам, таким как Lisp, FORTRAN или код Морзе.
Обработка естественного языка - важная часть ИИ, потому что язык тесно связан с мыслью.
Одним из показателей этого является количество важных книг, в названии которых упоминаются язык и мысль: в ИИ - *Компьютерные модели мысли и языка* Шэнка и Колби; в лингвистике - *Язык, мышление и реальность* Уорфа (и Хомского *Язык и разум;)* в философии - *Язык мышления* Фодора; в психологии - *Мысль и язык* Выготского и *Язык, память и мысль* Джона Андерсона. Действительно, язык - это черта, которую многие считают наиболее характерный для людей.
Много споров вызвал вопрос о том, могут ли животные, особенно приматы и дельфины, использовать и "понимать" язык.
Подобный спор связан с тем же вопросом, который задают о компьютерах.

Изучение языка традиционно делится на два широких класса: синтаксис, или грамматика, и семантика, или значение.
Исторически синтаксис привлекал к себе наибольшее внимание, в основном потому, что на первый взгляд он более податлив для формальных и полуформальных методов.
Хотя есть свидетельства того, что граница между ними в лучшем случае нечеткая, мы по-прежнему сохраняем различие для целей этих заметок.
Сначала мы рассмотрим "более простую" часть, синтаксис, а затем перейдем к семантике.

Хороший искусственный язык, такой как Лисп или Си, однозначен.
Есть только одна интерпретация действительного выражения Лиспа.
Конечно, интерпретация может зависеть от текущего состояния мира Лиспа, такого как значение глобальных переменных.
Но эти зависимости можно перечислить явно, и как только они будут прописаны, выражение может иметь только одно значение. [1](#fn0015)

Естественный язык так не работает.
Естественные выражения по своей природе неоднозначны, в зависимости от множества факторов, которые невозможно описать полностью.
Совершенно разумно, чтобы два человека не пришли к согласию относительно того, что другой человек имел в виду под выражением естественного языка.
(Адвокаты и судьи зарабатывают себе на жизнь в основном интерпретацией выражений на естественном языке - законов, которые должны быть недвусмысленными, но это не так.)

Эта глава представляет собой краткое введение в обработку естественного языка.
В следующей главе дается более подробное рассмотрение с точки зрения логических грамматик, а в следующей главе все это сведено воедино в полноценную систему.

## 19.1 Разбор с помощью грамматики фразовой структуры

Анализировать предложение означает восстанавливать составную структуру предложения - выяснять, какая последовательность правил генерации могла быть применена, чтобы составить предложение.
В общем, может быть несколько возможных путях вывода(производных), и в этом случае мы говорим, что предложение грамматически неоднозначно.
В определенных кругах термин "parse/синтаксический анализ" означает достижение понимания значения предложения, а не только его грамматической формы.
Позже мы ответим на этот более сложный вопрос.

Начнем с грамматики, определенной на [стр. 39](B9780080571157500029.xhtml#p39) для программы generate(создания):

```lisp
(defvar *grammar* nil "The grammar used by GENERATE.")

(defparameter *grammarl*
      '((Sentence -> (NP VP))
          (NP -> (Art Noun))
          (VP -> (Verb NP))
          (Art -> the a)
          (Noun -> man ball woman table)
          (Verb -> hit took saw liked)))
```

Наш синтаксический анализатор принимает на вход список слов и возвращает структуру, содержащую дерево синтаксического анализа и непроанализированные слова, если таковые имеются.
Таким образом, мы можем проанализировать оставшиеся слова в следующей категории, чтобы получить составные правила.
Например, при синтаксическом анализе "the man saw the table"(человек увидел таблицу/стол) мы сначала проанализируем "the man"(мужчина/человек), вернув стрктуру, представляющую именную фразу(noun phrase), с оставшимися словами "saw the table.(увидел стол). Этот остаток затем будет проанализирован как глагольная фраза(verb phrase), не возвращая остатка, и две фразы затем могут быть объединены в форму синтаксического анализа, который является полным предложением без остатка.

Прежде чем продолжить, я хочу изменить представление правил грамматики.
В настоящее время правила имеют левую часть и список альтернативных правых частей.
Но каждая из этих альтернатив - это действительно отдельное правило, поэтому было бы более модульным писать их отдельно.
Для программы `generate` было нормально иметь их все вместе, потому что это облегчало выбор обработки, но теперь мне нужно более гибкое представление.
Позже мы захотим добавить дополнительную информацию к каждому правилу, такую ​​как семантика собранной левой части и ограничения между составляющими в правой части, так что правила действительно стали бы довольно большими, если бы мы не разделились. альтернативы.
Я также пользуюсь этой возможностью, чтобы прояснить путаницу между словами и символами категорий.
По соглашению правая часть может быть либо атомом, и в этом случае это слово, либо списком символов, которые затем все интерпретируются как категории.
Чтобы подчеркнуть это, я включил "noun"(существительное) и "verb"(глагол) как существительные в грамматику `*grammar3*`, которая в остальном эквивалентна предыдущей `*grammarl*`.

```lisp
(defparameter *grammar3*
  '((Sentence -> (NP VP))
    (NP -> (Art Noun))
    (VP -> (Verb NP))
    (Art -> the) (Art -> a)
    (Noun -> man) (Noun -> ball) (Noun -> woman) (Noun -> table)
    (Noun -> noun) (Noun -> verb)
    (Verb -> hit) (Verb -> took) (Verb -> saw) (Verb -> liked)))

(setf *grammar* *grammar3*)
```

Я также определяю типы данных `rule, parse` и `tree`, а также некоторые функции для доступа к правилам.
Rule(Правила) определены как структуры типа list(списка) с тремя слотами: левая сторона, стрелка (которая всегда должна быть представлена как литерал ->) и правая сторона.
Сравните это с трактовкой на [стр. 40](B9780080571157500029.xhtml#p40).

```lisp
(defstruct (rule (:type list)) lhs -> rhs sem)

(defstruct (parse) "A parse tree and a remainder." tree rem)

;; Trees are of the form: (lhs . rhs)
(defun new-tree (cat rhs) (cons cat rhs))
(defun tree-lhs (tree) (first tree))
(defun tree-rhs (tree) (rest tree))

(defun parse-lhs (parse) (tree-lhs (parse-tree parse)))

(defun lexical-rules (word)
  "Return a list of rules with word on the right hand side."
  (or (find-all word *grammar* :key #'rule-rhs :test #'equal)
      (mapcar #'(lambda (cat) `(,cat -> ,word)) *open-categories*)))

(defun rules-starting-with (cat)
  "Return a list of rules where cat starts the rhs."
  (find-all cat *grammar*
            :key #'(lambda (rule) (first-or-nil (rule-rhs rule)))))

(defun first-or-nil (x)
  "The first element of x if it is a list; else nil."
  (if (consp x) (first x) nil))
```

Теперь мы готовы определить парсер.
Синтаксический анализатор(parser) основной функции принимает список слов для анализа.
Она вызывает синтаксический анализ(parse), которая возвращает список всех синтаксических анализов, которые анализируют некоторую подпоследовательность слов, начиная с начала.
parser сохраняет только синтаксический анализ без остатка, то есть синтаксический анализ, охватывающий все слова.

```lisp
(defun parser (words)
  "Return all complete parses of a list of words."
  (mapcar #'parse-tree (complete-parses (parse words))))

(defun complete-parses (parses)
  "Those parses that are complete (have no remainder)."
  (find-all-if #'null parses :key #'parse-rem))
```

Функция parse смотрит на первое слово и рассматривает каждую категорию, в которую оно может входить.
Она выполняет синтаксический анализ первого слова в каждой категории и вызывает `extend-parse`, чтобы попытаться продолжить полный синтаксический анализ.
parse использует `mapcan` для объединения всех результатов синтаксического анализа.
В качестве примера предположим, что мы пытаемся разобрать "the man took the ball."(мужчина взял мяч). parse найдет единственное лексическое правило для "the" и вызовет extend-parse с синтаксическим анализом с tree (Art the) и остатком "man took the ball" без дополнительных категорий.

У `extend-parse` есть два случая.
Если для частичного синтаксического анализа не требуется больше категорий, он возвращает сам синтаксический анализ вместе с любыми анализами, которые могут быть сформированы путем расширения синтаксических анализов, начиная с частичного анализа.
В нашем примере есть одно правило, начинающееся с `Art`, а именно `(NP -> (Art Noun))`, поэтому функция будет пытаться расширить дерево синтаксического анализа (`NP (Art the))` с остатком "man took the ball" с категорией существительного(`Noun`).
Вызов метода `extension-parse` представляет собой второй случай.
Сначала мы анализируем "man took the ball,", и для каждого синтаксического анализа, относящегося к категории `Noun`(Существительное) (будет только один), мы объединяем его с частичным синтаксическим анализом.
В этом случае мы получаем `(NP (Art the) (Noun man))`.
Это расширяется как предложение с необходимым VP, и в конечном итоге мы получаем синтаксический анализ полного списка слов.

```lisp
(defun parse (words)
  "Bottom-up parse, returning all parses of any prefix of words."
  (unless (null words)
    (mapcan #'(lambda (rule)
                (extend-parse (rule-lhs rule) (list (first words))
                              (rest words) nil))
            (lexical-rules (first words)))))

(defun extend-parse (lhs rhs rem needed)
  "Look for the categories needed to complete the parse."
  (if (null needed)
      ;; If nothing needed, return parse and upward extensions
      (let ((parse (make-parse :tree (new-tree lhs rhs) :rem rem)))
        (cons parse
              (mapcan
                #'(lambda (rule)
                    (extend-parse (rule-lhs rule)
                                  (list (parse-tree parse))
                                  rem (rest (rule-rhs rule))))
                (rules-starting-with lhs))))
      ;; otherwise try to extend rightward
      (mapcan
        #'(lambda (p)
            (if (eq (parse-lhs p) (first needed))
                (extend-parse lhs (append1 rhs (parse-tree p))
                              (parse-rem p) (rest needed))))
        (parse rem))))
```

Это использует вспомогательную функцию append1:

```lisp
(defun append1 (items item)
  "Add item to end of list of items."
  (append items (list item)))
```

Здесь показаны некоторые примеры работы парсера:

```lisp
> (parser '(the table))
((NP (ART THE) (NOUN TABLE)))
> (parser '(the ball hit the table))
((SENTENCE (NP (ART THE) (NOUN BALL))
                            (VP (VERB HIT)
                                      (NP (ARTTHE) (NOUN TABLE)))))
> (parser '(the noun took the verb))
((SENTENCE (NP (ART THE) (NOUN NOUN))
                            (VP (VERB TOOK)
                                      (NP (ARTTHE) (NOUN VERB)))))
```

## 19.2 Расширение грамматики и распознавание двусмысленности

В целом, парсер, похоже, работает нормально, но диапазон предложений, которые мы можем разобрать, весьма ограничен текущей грамматикой.
Следующая грамматика включает более широкий спектр языковых фонем: прилагательные(adjectives), предложные(prepositional) фразы - Устойчивые выражения с предлогами, местоимения(pronouns) и имена собственные(proper names).
Она также использует обычные лингвистические соглашения для названий категорий, кратко изложенные в таблице ниже:

|      | Category                         | Examples                   |
|------|----------------------------------|----------------------------|
| S    | Sentence                         | *John likes Mary*          |
| NP   | Noun Phrase                      | *John; a blue table*       |
| VP   | Verb Phrase                      | *likes Mary; hit the ball* |
| PP   | Prepositional Phrase             | *to Mary; with the man*    |
| A    | Adjective                        | *little; blue*             |
| A  + | A list of one or more adjectives | *little blue*              |
| D    | Determiner                       | *the; a*                   |
| N    | Noun                             | *ball; table*              |
| Name | Proper Name                      | *John; Mary*               |
| P    | Preposition                      | *to; with*                 |
| Pro  | Pronoun                          | *you; me*                  |
| V    | Verb                             | *liked; hit*               |

Вот грамматика:

```lisp
(defparameter *grammar4*
  '((S -> (NP VP))
    (NP -> (D N))
    (NP -> (D A+ N))
    (NP -> (NP PP))
    (NP -> (Pro))
    (NP -> (Name))
    (VP -> (V NP))
    (VP -> (V))
    (VP -> (VP PP))
    (PP -> (P NP))
    (A+ -> (A))
    (A+ -> (A A+))
    (Pro -> I) (Pro -> you) (Pro -> he) (Pro -> she)
    (Pro -> it) (Pro -> me) (Pro -> him) (Pro -> her)
    (Name -> John) (Name -> Mary)
    (A -> big) (A -> little) (A -> old) (A -> young)
    (A -> blue) (A -> green) (A -> orange) (A -> perspicuous)
    (D -> the) (D -> a) (D -> an)
    (N -> man) (N -> ball) (N -> woman) (N -> table) (N -> orange)
    (N -> saw) (N -> saws) (N -> noun) (N -> verb)
    (P -> with) (P -> for) (P -> at) (P -> on) (P -> by) (P -> of) (P -> in)
    (V -> hit) (V -> took) (V -> saw) (V -> liked) (V -> saws)))

(setf *grammar* *grammar4*)
```

Теперь мы можем разбирать более интересные предложения и можем увидеть явление, которого не было в предыдущих примерах: неоднозначные предложения.
Предложение "The man hit the table with the ball"("Человек ударил мячом по столу") имеет два анализа, в одном из где мяч(ball) - это предмет, который попадает в стол(table), а в другом - когда мяч находится на столе или рядом с ним, синтаксический анализатор находит оба этих анализа (хотя конечно, он не придает никакого значения/смысла ни одному синтаксическому анализу):

```lisp
> (parser '(The man hit the table with the ball))
((S (NP (D THE) (N MAN))
      (VP (VP (V HIT) (NP (D THE) (N TABLE)))
          (PP (P WITH) (NP (DTHE) (N BALL)))))
(S (NP (D THE) (N MAN))
      (VP (V HIT)
          (NP (NP (D THE) (N TABLE))
                        (PP (P WITH) (NP (DTHE) (N BALL)))))))
```

Предложения(Sentences) - не единственная категория, которая может быть неоднозначной, и не все неоднозначности должны быть между синтаксическими анализами в одной и той же категории.
Здесь мы видим двусмысленную фразу между предложением и фразой существительного(noun phrase):

```lisp
> (parser '(the orange saw))
((S (NP (D THE) (N ORANGE)) (VP (V SAW)))
  (NP (D THE) (A  + (A ORANGE)) (N SAW)))
```

## 19.3 Более эффективный анализ

При использовании более сложных грамматик и более длинных предложений синтаксический анализатор начинает замедляться.
Основная проблема в том, что он постоянно повторяет работу.
Например, при синтаксическом анализе "The man hit the table with the ball,"(Человек ударил мячом по столу) он должен повторить анализ "with the ball" для обоих результирующих синтаксических анализов, даже если в обоих случаях он получает один и тот же анализ, PP.
Мы видели эту проблему раньше и уже получили ответ: мемоизация (см. [Раздел 9.6](#s0035)).
Чтобы увидеть, насколько поможет мемоизация, нам нужен тест:

```lisp
> (setf s (generate 's))
(THE PERSPICUOUS BIG GREEN BALL BY A BLUE WOMAN WITH A BIG MAN
    HIT A TABLE BY THE SAW BY THE GREEN ORANGE)
> (time (length (parser s)))
Evaluation of (LENGTH (PARSER S)) took 33.11 Seconds of elapsed time.
10
```

Предложение S имеет 10 синтаксических разборов, поскольку есть два способа синтаксического анализа подлежащего NP и пять способов синтаксического анализа VP.
На обнаружение этих 10 синтаксических анализов с помощью функции синтаксического анализа в том виде, в котором она была написана, потребовалось 33 секунды.

Мы можем значительно улучшить это, запомнив синтаксический анализ (вместе с функциями поиска по таблице).
Помимо мемоизации, единственное изменение - очистить таблицу мемоизации в парсере.

```lisp
(memoize 'lexical-rules)
(memoize 'rules-starting-with)
(memoize 'parse :test #'eq)

(defun parser (words)
  "Return all complete parses of a list of words."
  (clear-memoize 'parse) ;***
  (mapcar #'parse-tree (complete-parses (parse words))))
```

При обычном использовании человеческого языка мемоизация не будет работать очень хорошо, поскольку интерпретация фразы зависит от контекста, в котором она была произнесена.
Но с контекстно-свободными грамматиками у нас есть гарантия, что контекст не может повлиять на интерпретацию.
Вызов `(parse words)` должен возвращать все возможные синтаксические разборы слов.
Мы свободны выбирать между возможностями, основанными на контекстной информации, но контекст никогда не может предоставить новую интерпретацию, которая не входит в контекстно-свободный список синтаксических анализов.

Функция `use` вводиться, чтобы сообщить функциям поиска в таблице, что они устарели при изменении грамматики:

```lisp
(defun use (grammar)
  "Switch to a new grammar."
  (clear-memoize 'rules-starting-with)
  (clear-memoize 'lexical-rules)
  (length (setf *grammar* grammar)))
```

Теперь мы снова запускаем тест с мемоизированной версией синтаксического анализа:

```lisp
> (time (length (parser s)))
Evaluation of (LENGTH (PARSER S 's)) took .13 Seconds of elapsed time.
10
```

Мемоизируя `parse`, мы сокращаем время синтаксического анализа с 33 до 13 секунд, ускорение 250 процентов.
Мы можем получить более систематическое сравнение, посмотрев на ряд примеров.
Например, рассмотрите предложения формы "The man hit the table [with the ball]*"(Человек ударил по столу [мячом]) для нуля или более повторений PP "with the ball"(с мячом). В следующей таблице мы записываем N, количество повторений PP, вместе с количеством результирующих синтаксических анализов, [2](# fn0020) и для мемоизированных и немомизированных версий синтаксического анализа, количество секунд для выполнения синтаксического анализа, количество парсингов в секунду (PPS) и количество рекурсивных вызовов parse.
Производительность мемоизированной версии вполне приемлема; для N = 5 предложение из 20 слов разбирается на 132 варианта за 0,68 секунды, в отличие от 20 секунд, которые требуются в незапоминающей версии.

|      |        | Memoized |     |       | Unmemoized |     |       |
| N    | Parses | Secs     | PPS | Calls | Secs       | PPS | Calls |
|------|--------|----------|-----|-------|------------|-----|-------|
| 0    | 1      | 0.02     | 60  | 4     | 0.02       | 60  | 17    |
| 1    | 2      | 0.02     | 120 | 11    | 0.07       | 30  | 96    |
| 2    | 5      | 0.05     | 100 | 21    | 0.23       | 21  | 381   |
| 3    | 14     | 0.10     | 140 | 34    | 0.85       | 16  | 1388  |
| 4    | 42     | 0.23     | 180 | 50    | 3.17       | 13  | 4999  |
| 5    | 132    | 0.68     | 193 | 69    | 20.77      | 6   | 18174 |
| 6    | 429    | 1.92     | 224 | 91    | -          |     |       |
| 7    | 1430   | 5.80     | 247 | 116   | -          |     |       |
| 8    | 4862   | 20.47    | 238 | 144   | -          |     |       |

**Упражнение 19.1 [h]** Кажется, что мы могли бы быть более эффективными, если бы запомнили таблицу, состоящую из вектора, длина которого равна количеству слов во входных данных (плюс один).
Реализуйте этот подход и посмотрите, повлечет ли он меньше накладных расходов, чем более общий подход с хэш-таблицей.

## 19.4 Проблема с неизвестным словом

В его нынешнем виде парсер не может работать с неизвестными словами.
Любое предложение, содержащее слово, которого нет в грамматике, будет отклонено, даже если программа сможет идеально проанализировать все остальные слова.
Один из способов обращения с неизвестными словами - позволить им быть любой из категорий "open-class"(открытого класса) - существительными, глаголами, прилагательными и именами в нашей грамматике.
Неизвестное слово не будет рассматриваться как одна из категорий "closed-class"(закрытого класса) - предлогов, определителей или местоимений.
Это можно очень просто запрограммировать, заставив `lexical-rules` возвращать список этих правил открытого класса для каждого слова, которое еще не известно.

```lisp
(defparameter *open-categories* '(N V A Name)
  "Categories to consider for unknown words")

(defun lexical-rules (word)
  "Return a list of rules with word on the right hand side."
  (or (find-all word *grammar* :key #'rule-rhs :test #'equal)
      (mapcar #'(lambda (cat) `(,cat -> ,word)) *open-categories*)))
```

При запоминании лексических правил это означает, что лексикон расширяется каждый раз, когда встречается неизвестное слово.
Давайте попробуем это:

```lisp
> (parser '(John liked Mary))
((S (NP (NAME JOHN))
            (VP (V LIKED) (NP (NAME MARY)))))
> (parser '(Dana liked Dale))
((S (NP (NAME DANA))
            (VP (V LIKED) (NP (NAME DALE)))))
> (parser '(the rab zaggled the woogly quax))
((S (NP (D THE) (N RAB))
            (VP (V ZAGGLED) (NP (D THE) (A  + (A WOOGLY)) (N QUAX)))))
```

Мы видим, что синтаксический анализатор также работает со словами, которые он знает (Джон и Мэри), так и с новыми словами (Дана и Дейл), которые он может распознавать как имена из-за их положения в предложении.
В последнем предложении в примере он однозначно распознает каждое неизвестное слово.
К сожалению, не всегда все так просто, как показывают следующие примеры:

```lisp
> (parser '(the slithy toves gymbled))
((S (NP (D THE) (N SLITHY)) (VP (V TOVES) (NP (NAME GYMBLED))))
  (S (NP (D THE) (A  + (A SLITHY)) (N TOVES)) (VP (V GYMBLED)))
  (NP (D THE) (A  + (A SLITHY) (A  + (A TOVES))) (N GYMBLED)))
> (parser '(the slithy toves gymbled on the wabe))
((S (NP (D THE) (N SLITHY))
      (VP (VP (V TOVES) (NP (NAME GYMBLED)))
            PP (P ON) (NP (D THE) (N WABE)))))
(S (NP (D THE) (N SLITHY))
      (VP (V TOVES) (NP (NP (NAME GYMBLED))
            (PP (P ON) (NP (D THE) (N WABE))))))
(S (NP (D THE) (A  + (A SLITHY)) (N TOVES))
        (VP (VP (V GYMBLED)) (PP (P ON) (NP (D THE) (N WABE)))))
(NP (NP (D THE) (A  + (A SLITHY) (A  + (A TOVES))) (N GYMBLED))
        (PP (P ON) (NP (D THE) (N WABE)))))
```

Если бы программа знала морфологию - что *y* в конце слова часто означает прилагательное(adjective), *s* - существительное во множественном числе, а *ed* - глагол в прошедшем времени, - тогда он мог бы добиться большего.

## 19.5 Анализ семантического представления

Синтаксические деревья синтаксического разбора предложения могут быть интересными, но сами по себе они не очень полезны.
Мы используем предложения для передачи идей, а не для отображения грамматических структур.
Чтобы исследовать идею семантики или значения фразы, нам нужна область для обсуждения.
Представьте себе сценарий проигрывателя  компакт-дисков, способного воспроизводить выбранные песни на основе их номеров треков.
Далее представьте, что на передней панели этой машины есть кнопки, обозначающие числа, а также такие слова, как "play"(играть), "to"(до), "and"(и) и "without"(без). Если затем вы нажмете последовательность кнопок "play 1 to 5 without 3"(воспроизвести с 1 по 5 без 3), можно было бы разумно ожидать, что машина отреагирует воспроизведением треков 1, 2, 4 и 5.
После нескольких таких успешных взаимодействий можно сказать, что машина "понимает" ограниченный язык.
Важным моментом является то, что полезность этой машины не сильно улучшилась бы, если бы она отображала дерево синтаксического анализа входных данных.
С другой стороны, вы были бы оправданно раздражены, если бы она отреагировала на "play 1 to 5 without 3", сыграв 3 или пропустив 4.

Теперь давайте расширим воображение еще раз, предположив, что этот проигрыватель компакт-дисков оснащен полным компилятором Common Lisp, и что теперь мы отвечаем за написание синтаксического анализатора для его языка ввода.
Давайте сначала рассмотрим соответствующие структуры данных.
Нам нужно добавить компонент семантики как в структуру правил, так и в древовидную структуру.
Как только мы это сделаем, станет ясно, что деревья - это не что иное, как экземпляры правил, поэтому их определения должны это отражать.
Таким образом, я использую команду: include defstruct для определения деревьев, и я не указываю функцию  копирования, потому что  copy-tree уже является функцией Common Lisp, и я не хочу ее переопределять.
Чтобы поддерживать согласованность со старой функцией new-tree (и чтобы не вводить все эти ключевые слова), я определяю конструктор `new-tree`.
Эта опция `defstruct makes (new-tree a b c)` эквивалентна `(make-tree :lhs a :sem b :rhs c)`.

```lisp
(defstruct (rule (:type list)) lhs -> rhs sem)

(defstruct (tree (:type list) (:include rule) (:copier nil)
                 (:constructor new-tree (lhs sem rhs))))
```

Мы примем соглашение, согласно которому семантика слова может быть любым объектом Lisp.
Например, семантика слова "1" может быть объектом 1, а семантика "without"(без) может быть функцией `set-difference`.
Семантика дерева формируется путем взятия семантики правила, которое сгенерировало дерево, и ее применения (как функции) к семантике составляющих дерева.
Таким образом, автор грамматики должен убедиться, что семантический компонент правил - это функции, которые ожидают правильное количество аргументов.
Например, учитывая правило

```lisp
(NP -> (NP CONJ NP) infix-funcall)
```

тогда семантика фразы "1 to 5 without 3" может быть определена путем определения сначала семантикой "1 to 5"(от 1 до 5) как (1 2 3 4 5), "without" как `set-difference` и 3 как (3).
После того, как эти подкомпоненты определены, правило применяется путем вызова функции `infix-funcall` с тремя аргументами (1 2 3 4 5), `set-difference` и (3).
Предполагая, что `infix-funcall` определен для применения своего второго аргумента к двум другим аргументам, результат будет (1 2 4 5).

Это может иметь больше смысла, если мы посмотрим на полную грамматику проблемы с проигрывателем компакт-дисков:

```lisp
(use
  '((NP -> (NP CONJ NP) infix-funcall)
    (NP -> (N)          list)
    (NP -> (N P N)      infix-funcall)
    (N ->  (DIGIT)      identity)
    (P ->  to           integers)
    (CONJ -> and        ordered-union)
    (CONJ -> without    ordered-set-difference)
    (N -> 1 1) (N -> 2 2) (N -> 3 3) (N -> 4 4) (N -> 5 5)
    (N -> 6 6) (N -> 7 7) (N -> 8 8) (N -> 9 9) (N -> 0 0)))

(defun integers (start end)
  "A list of all the integers in the range [start...end] inclusive."
  (if (> start end) nil
      (cons start (integers (+ start 1) end))))

(defun infix-funcall (arg1 function arg2)
  "Apply the function to the two arguments"
  (funcall function arg1 arg2))
```

Рассмотрим первые три грамматических правила, которые являются единственными нелексическими правилами.
Первое говорит, что когда два NP соединяются conjunction(соединением), мы предполагаем, что перевод соединения будет функцией, а перевод фразы в целом получается путем вызова этой функции с переводами двух NP в качестве аргументов.
Второе правило гласит, что одно существительное (перевод которого должен быть числом) переводится в одноэлементный список, состоящий из этого числа.
Третье правило похоже на первое, но касается joining(присоединения) Ns, а не NP.
Общая цель состоит в том, чтобы перевод NP всегда был списком целых чисел, представляющих песни для воспроизведения.

Что касается лексических правил, союз "and"(и) переводится в функцию union(объединения), "without"(без) переводится в функцию, которая вычитает один набор из другого, а "to"(в) переводится в функцию, которая генерирует список целых чисел между двумя конечными точками.
Цифры от "0" до "9" переводятся сами в себя.
Обратите внимание, что как лексические правила, такие как "`CONJ ->` and", так и нелексические правила, такие как "`NP -> (N P N)`", могут иметь функции в качестве своих семантических переводов; в первом случае функция будет просто возвращена как семантический перевод, тогда как во втором случае функция будет применена к списку составляющих.

Для поддержки такого рода семантической обработки требуются лишь незначительные изменения.
Как мы увидим ниже, мы добавляем аргумент sem для расширения - синтаксического анализа и упорядочивания для правильной передачи семантических компонентов.
Когда мы собрали все компоненты с правой стороны, мы фактически выполняем применение(вызов) функции.
Все изменения отмечены ***.
Мы принимаем соглашение, согласно которому семантическое значение `nil` указывает на сбой, и отбрасываем все такие синтаксические анализы.

```lisp
(defun parse (words)
  "Bottom-up parse, returning all parses of any prefix of words.
  This version has semantics."
  (unless (null words)
    (mapcan #'(lambda (rule)
                (extend-parse (rule-lhs rule) (rule-sem rule) ;***
                              (list (first words)) (rest words) nil))
            (lexical-rules (first words)))))

(defun extend-parse (lhs sem rhs rem needed) ;***
  "Look for the categories needed to complete the parse.
  This version has semantics."
  (if (null needed)
      ;; If nothing is needed, return this parse and upward extensions,
      ;; unless the semantics fails
      (let ((parse (make-parse :tree (new-tree lhs sem rhs) :rem rem)))
        (unless (null (apply-semantics (parse-tree parse))) ;***
          (cons parse
                (mapcan
                  #'(lambda (rule)
                      (extend-parse (rule-lhs rule) (rule-sem rule) ;***
                                    (list (parse-tree parse)) rem
                                    (rest (rule-rhs rule))))
                  (rules-starting-with lhs)))))
      ;; otherwise try to extend rightward
      (mapcan
        #'(lambda (p)
            (if (eq (parse-lhs p) (first needed))
                (extend-parse lhs sem (append1 rhs (parse-tree p)) ;***
                              (parse-rem p) (rest needed))))
        (parse rem))))
```

Нам нужно добавить несколько новых функций для поддержки этого:

```lisp
(defun apply-semantics (tree)
  "For terminal nodes, just fetch the semantics.
  Otherwise, apply the sem function to its constituents."
  (if (terminal-tree-p tree)
      (tree-sem tree)
      (setf (tree-sem tree)
            (apply (tree-sem tree)
                   (mapcar #'tree-sem (tree-rhs tree))))))

(defun terminal-tree-p (tree)
  "Does this tree have a single word on the rhs?"
  (and (length=1 (tree-rhs tree))
       (atom (first (tree-rhs tree)))))

(defun meanings (words)
  "Return all possible meanings of a phrase.  Throw away the syntactic part."
  (remove-duplicates (mapcar #'tree-sem (parser words)) :test #'equal))
```

Вот несколько примеров значений, которые может извлечь парсер:

(meanings '(1 to 5 without 3))

((1 2 4 5))

(meanings '(1 to 4 and 7 to 9))

((1 2 3 4 7 8 9))

(meanings '(1 to 6 without 3 and 4))

((12 4 5 6)

(1 2 5 6))

Пример "(1 to 6 without 3 and 4)"-(от 1 до 6 без 3 и 4)  неоднозначен.
Первое прочтение соответствует "((1 to 6) without 3) and 4", а второе соответствует "(1 to 6) without (3 and 4)". Синтаксическая неоднозначность приводит к семантической неоднозначности - два значения имеют в себе разные списки чисел.
Однако кажется, что второе прочтение в чем-то лучше, поскольку не имеет большого смысла говорить о добавлении 4 к набору, который уже включает его, что и делает первый перевод.

Мы можем обновить лексикон, чтобы учесть это.
Следующая лексика утверждает, что "and" соединяет непересекающиеся множества и что "without" удаляет только элементы, которые уже были в первом аргументе.
Если эти условия не выполняются, перевод вернет nil, и синтаксический анализ завершится неудачно.
Обратите внимание, что это также означает, что пустой список, такой как "3 to 2"» также не сработает.

Предыдущая грамматика допускала только цифры от 0 до 9.
Мы можем допустить большее число, соединяя цифры вместе.
Итак, теперь у нас есть два правила для чисел: число - это либо одна цифра, и в этом случае значение является самой цифрой (функция identity), либо это число, за которым следует другая цифра, и в этом случае значение равно 10-кратное число плюс цифра.
В качестве альтернативы мы могли бы указать число как цифру, за которой следует число, или даже число, за которым следует число, но любая из этих формулировок потребует более сложной семантической интерпретации.

```lisp
(use
  '((NP -> (NP CONJ NP) infix-funcall)
    (NP -> (N)          list)
    (NP -> (N P N)      infix-funcall)
    (N ->  (DIGIT)      identity)
    (N ->  (N DIGIT)    10*N+D)
    (P ->  to           integers)
    (CONJ -> and        union*)
    (CONJ -> without    set-diff)
    (DIGIT -> 1 1) (DIGIT -> 2 2) (DIGIT -> 3 3)
    (DIGIT -> 4 4) (DIGIT -> 5 5) (DIGIT -> 6 6)
    (DIGIT -> 7 7) (DIGIT -> 8 8) (DIGIT -> 9 9)
    (DIGIT -> 0 0)))

(defun union* (x y) (if (null (intersection x y)) (append x y)))
(defun set-diff (x y) (if (subsetp y x) (ordered-set-difference x y)))
(defun 10*N+D (N D) (+ (* 10 N) D))
```

С помощью этой новой грамматики мы можем получить единственные интерпретации из наиболее разумных входных данных:

```lisp
> (meanings '(1 to 6 without 3 and 4))
((1 2 5 6))
> (meanings '(1 and 3 to 7 and 9 without 5 and 6))
((13 4 7 9))
> (meanings '(1 and 3 to 7 and 9 without 5 and 2))
((1 3 4 6 7 9 2))
> (meanings '(1 9 8 to 2 0 1))
((198 199 200 201))
> (meanings '(1 2 3))
(123 (123))
```

Пример "1 2 3" показывает неоднозначность между числом 123 и списком (123), но все остальные однозначны.

## 19.6 Разбор с Предпочтениями(Preferences)

Одна из причин, по которой у нас есть однозначные интерпретации, заключается в том, что у нас очень ограниченная область интерпретации: мы имеем дело с наборами чисел, а не со списками.
Это, возможно, типично для запросов, с которыми сталкивается проигрыватель компакт-дисков, но не учитывает весь желаемый ввод.
Например, если у вас была любимая песня, вы не могли услышать ее трижды с запросом "1 and 1 and 1" по этой грамматике.
Нам нужен некоторый компромисс между разрешающей грамматикой, которая генерирует все возможные синтаксические анализы, и ограничительной грамматикой, которая устраняет слишком много синтаксических анализов.
Чтобы получить "лучшую" интерпретацию произвольного ввода, нам потребуется не только новая грамматика, но и модифицировать программу, чтобы сравнить относительную ценность возможных интерпретаций.
Другими словами, мы присвоим каждой интерпретации числовой балл, а затем выберем интерпретацию с наивысшим баллом.

Мы начнем с того, что еще раз изменим  правила и дерево типов данных, чтобы включить в них компонент оценки.
Как и в случае с компонентом sem, он будет использоваться для хранения сначала функции для вычисления оценки, а затем, в конечном итоге, самой оценки.

```lisp
(defstruct (rule (:type list)
                 (:constructor rule (lhs -> rhs &optional sem score)))
  lhs -> rhs sem score)

(defstruct (tree (:type list) (:include rule) (:copier nil)
                 (:constructor new-tree (lhs sem score rhs))))
```

Обратите внимание, что мы добавили функцию-конструктор `rule`.
Намерение состоит в том, что компоненты sem и score в правилах грамматики должны быть необязательными(опциональными).
Пользователь не обязан их указывать, но использование функции гарантирует, что функция rule будет вызвана для заполнения отсутствующих значений sem и score с помощью nil.

```lisp
(defun use (grammar)
  "Switch to a new grammar."
  (clear-memoize 'rules-starting-with)
  (clear-memoize 'lexical-rules)
  (length (setf *grammar*
                (mapcar #'(lambda (r) (apply #'rule r))
                        grammar))))
```

Теперь модифицируем синтаксический анализатор, чтобы отслеживать баллы(score).
Изменения снова незначительны и отражают изменения, необходимые для добавления семантики.
Есть два места, где мы помещаем баллы в деревья при их создании, и одно место, где мы применяем функцию подсчета баллов к её аргументам.

```lisp
(defun parse (words)
  "Bottom-up parse, returning all parses of any prefix of words."
  This version has semantics and preference scores."
  (unless (null words)
    (mapcan #'(lambda (rule)
                (extend-parse (rule-lhs rule) (rule-sem rule)
                              (rule-score rule) (list (first words)) ;***
                              (rest words) nil))
            (lexical-rules (first words)))))

(defun extend-parse (lhs sem score rhs rem needed) ;***
  "Look for the categories needed to complete the parse.
  This version has semantics and preference scores."
  (if (null needed)
      ;; If nothing is needed, return this parse and upward extensions,
      ;; unless the semantics fails
      (let ((parse (make-parse :tree (new-tree lhs sem score rhs) ;***
                               :rem rem)))
        (unless (null (apply-semantics (parse-tree parse)))
          (apply-scorer (parse-tree parse)) ;***
          (cons parse
                (mapcan
                  #'(lambda (rule)
                      (extend-parse
                        (rule-lhs rule) (rule-sem rule)
                        (rule-score rule) (list (parse-tree parse)) ;***
                        rem (rest (rule-rhs rule))))
                  (rules-starting-with lhs)))))
      ;; otherwise try to extend rightward
      (mapcan
        #'(lambda (p)
            (if (eq (parse-lhs p) (first needed))
                (extend-parse lhs sem score
                              (append1 rhs (parse-tree p)) ;***
                              (parse-rem p) (rest needed))))
        (parse rem))))
```

И снова нам нужны новые функции для поддержки этого.
Самой важной является `apply-scorer`, которая вычисляет баллы для дерева.
Если дерево является терминалом (словом), тогда функция просто ищет оценку(баллы), связанную с этим словом.
В этой грамматике все слова имеют оценку 0, но в грамматике с неоднозначными словами было бы неплохо дать более низкие оценки для редко используемых значений неоднозначных слов.
Если дерево нетерминальное, то оценка(баллы) вычисляется в два этапа.
Сначала складываются все баллы составляющих дерева.
Затем это добавляется к мере для дерева в целом.
Правило, связанное с каждым деревом, будет иметь либо номер, который добавляется к сумме, либо функцию.
В последнем случае функция применяется к дереву, и результат добавляется для получения окончательной оценки.
В качестве последнего особого случая, если функция возвращает nil, мы предполагаем, что она должна была вернуть ноль.
Это упростит определение некоторых функций подсчета очков.

```lisp
(defun apply-scorer (tree)
  "Compute the score for this tree."
  (let ((score (or (tree-score tree) 0)))
    (setf (tree-score tree)
          (if (terminal-tree-p tree)
              score
              ;; Add up the constituent's scores,
              ;; along with the tree's score
              (+ (sum (tree-rhs tree) #'tree-score-or-0)
                 (if (numberp score)
                     score
                     (or (apply score (tree-rhs tree)) 0)))))))
```

Вот функция доступа, позволяющая выбрать баллы из дерева:

```lisp
(defun tree-score-or-0 (tree)
    (if (numberp (tree-score tree)) (tree-score tree) 0))
```

Вот обновленная грамматика.
Во-первых, я не мог отказаться от возможности добавить больше возможностей в грамматику.
Я добавил постноминальные прилагательные "shuffled"(перемешанный), которые случайным образом меняют  список песен, и "reversed"(обратный), который меняет порядок воспроизведения на обратный.
Я также добавил оператор "repeat"(повтор), например "1 to 3 repeat 5", который повторяет список определенное количество раз.
Я также добавил скобки, чтобы разрешить ввод, который явно говорит о том, как его следует анализировать.

```lisp
(use
  '((NP -> (NP CONJ NP) infix-funcall  infix-scorer)
    (NP -> (N P N)      infix-funcall  infix-scorer)
    (NP -> (N)          list)
    (NP -> ([ NP ])     arg2)
    (NP -> (NP ADJ)     rev-funcall    rev-scorer)
    (NP -> (NP OP N)    infix-funcall)
    (N  -> (D)          identity)
    (N  -> (N D)        10*N+D)
    (P  -> to           integers       prefer<)
    ([  -> [            [)
    (]  -> ]            ])
    (OP -> repeat       repeat)
    (CONJ -> and        append         prefer-disjoint)
    (CONJ -> without    ordered-set-difference prefer-subset)
    (ADJ -> reversed    reverse        inv-span)
    (ADJ -> shuffled    permute        prefer-not-singleton)
    (D -> 1 1) (D -> 2 2) (D -> 3 3) (D -> 4 4) (D -> 5 5)
    (D -> 6 6) (D -> 7 7) (D -> 8 8) (D -> 9 9) (D -> 0 0)))
```

Следующие функции оценки принимают деревья в качестве входных данных и вычисляют бонусы или штрафы для этих деревьев.
Функция подсчета баллов `prefer<`, используемая для слова "to"(к), дает штраф в один балл за обратные диапазоны: "5 to 1" получает оценку -1, в то время как "1 to 5" получает оценку 0.
scorer(функция подсчета баллов) для "and", `prefer-disjoint`, дает штраф в один балл для пересечения списков: "1 to 3 and 7 to 9" получает оценку 0(нет пересечения), а "1 to 4 and 2 to 5" получает - 1.
Функция подсчета баллов "x without y"(x без y), `prefer-subset`, дает трехочковый штраф, если в списке y есть элементы, которых нет в списке x.
Она также присуждает очки обратно пропорционально длине (в словах) фразе x.
Идея в том, что мы должны предпочесть жестко привязать "without" к какому-нибудь небольшому выражению слева.
Если окончательные оценочные баллы оказываются положительными или нецелыми, то ответственным является этот компонент подсчета, поскольку все другие компоненты являются отрицательными целыми числами.
Функция подсчета баллов "x shuffled",  `prefer-not-singleton`, аналогична, за исключением того, что здесь штрафом является перетасовка списка из менее чем двух песен.

```lisp
(defun prefer< (x y) (if (>= (sem x) (sem y)) -1))
(defun prefer-disjoint (x y) (if (intersection (sem x) (sem y)) -1))
(defun prefer-subset (x y)
  (+ (inv-span x) (if (subsetp (sem y) (sem x)) 0 -3)))
(defun prefer-not-singleton (x)
  (+ (inv-span x) (if (< (length (sem x)) 2) -4 0)))
```

Функции i`infix-scorer` и `rev-scorer` не добавляют ничего нового, они просто гарантируют, что ранее упомянутые функции подсчета баллов будут применены в нужном месте.

```lisp
(defun infix-scorer (arg1 scorer arg2)
  (funcall (tree-score scorer) arg1 arg2))

(defun rev-scorer (arg scorer) (funcall (tree-score scorer) arg))
```

Вот функции, упомянутые в грамматике, а также некоторые полезные утилиты:

```lisp
(defun arg2 (a1 a2 &rest a-n) (declare (ignore a1 a-n)) a2)

(defun rev-funcall (arg function) (funcall function arg))

(defun repeat (list n)
  "Append list n times."
  (if (= n 0)
      nil
      (append list (repeat list (- n 1)))))

(defun span-length (tree)
  "How many words are in tree?"
  (if (terminal-tree-p tree) 1
      (sum (tree-rhs tree) #'span-length)))

(defun inv-span (tree) (/ 1 (span-length tree)))

(defun sem (tree) (tree-sem tree))

(defun integers (start end)
  "A list of all the integers in the range [start...end] inclusive.
  This version allows start > end."
  (cond ((< start end) (cons start (integers (+ start 1) end)))
        ((> start end) (cons start (integers (- start 1) end)))
        (t (list start))))

(defun sum (numbers &optional fn)
  "Sum the numbers, or sum (mapcar fn numbers)."
  (if fn
      (loop for x in numbers sum (funcall fn x))
      (loop for x in numbers sum x)))

(defun permute (bag)
  "Return a random permutation of the given input list."
  (if (null bag)
      nil
      (let ((e (random-elt bag)))
        (cons e (permute (remove e bag :count 1 :test #'eq))))))
```

Нам понадобится способ показать рейтинг предпочтений:

```lisp
(defun all-parses (words)
  (format t "~%Score  Semantics~25T~a" words)
  (format t "~%=====  =========~25T============================~%")
  (loop for tree in (sort (parser words) #'> :key #'tree-score)
    do (format t "~5,1f  ~9a~25T~a~%" (tree-score tree) (tree-sem tree)
               (bracketing tree)))
  (values))

(defun bracketing (tree)
  "Extract the terminals, bracketed with parens."
  (cond ((atom tree) tree)
        ((length=1 (tree-rhs tree))
         (bracketing (first (tree-rhs tree))))
        (t (mapcar #'bracketing (tree-rhs tree)))))
```

Теперь мы можем попробовать несколько примеров:

```
> (all-parses '(1 to 6 without 3 and 4))
```

| []()      |                |                                |
|-----------|----------------|--------------------------------|
| `Score`   | `Semantics`    | `(1 TO 6 WITHOUT 3 AND 4)`     |
| `=======` | `===========`  | `========================`     |
| `0.3`     | `(12 5 6)`     | `((1 TO 6) WITHOUT (3 AND 4))` |
| `-0.7`    | `(12 4 5 6 4)` | `(((1 TO 6) WITHOUT 3) AND 4)` |

```
> (all-parses '(1 and 3 to 7 and 9 without 5 and 6))
```

| []()      |                     |                                                |
|-----------|---------------------|------------------------------------------------|
| `Score`   | `Semantics`         | `(1 AND 3 T0 7 AND 9 WITHOUT 5 AND 6)`         |
| `=======` | `===========`       | `=================================`            |
| `0.2`     | `(1 3 4 7 9)`       | `(1 AND (((3 T0 7) AND 9) WITHOUT (5 AND 6)))` |
| `0.1`     | `(1 3 4 7 9)`       | `(((1 AND (3 T0 7)) AND 9) WITHOUT (5 AND 6))` |
| `0.1`     | `(1 3 4 7 9)`       | `((1 AND ((3 T0 7) AND 9)) WITHOUT (5 AND 6))` |
| `-0.8`    | `(1 3 4 6 7 9 6)`   | `((1 AND (((3 T0 7) AND 9) WITHOUT 5)) AND 6)` |
| `-0.8`    | `(1 3 4 6 7 9 6)`   | `(1 AND ((((3 T0 7) AND 9) WITHOUT 5) AND 6))` |
| `-0.9`    | `(1 3 4 6 7 9 6)`   | `((((1 AND (3 T0 7)) AND 9) WITHOUT 5) AND 6)` |
| `-0.9`    | `(1 3 4 6 7 9 6)`   | `(((1 AND ((3 T0 7) AND 9)) WITHOUT 5) AND 6)` |
| `-2.0`    | `(1 3 4 5 6 7 9)`   | `((1 AND (3 TO 7)) AND (9 WITHOUT (5 AND 6)))` |
| `-2.0`    | `(1 3 4 5 6 7 9)`   | `(1 AND ((3 TO 7) AND (9 WITHOUT (5 AND 6))))` |
| `-3.0`    | `(1 3 4 5 6 7 9 6)` | `(((1 AND (3 TO 7)) AND (9 WITHOUT 5)) AND 6)` |
| `-3.0`    | `(1 3 4 5 6 7 9 6)` | `((1 AND (3 TO 7)) AND ((9 WITHOUT 5) AND 6))` |
| `-3.0`    | `(1 3 4 5 6 7 9 6)` | `((1 AND ((3 TO 7) AND (9 WITHOUT 5))) AND 6)` |
| `-3.0`    | `(1 3 4 5 6 7 9 6)` | `(1 AND (((3 T0 7) AND (9 WITHOUT 5)) AND 6))` |
| `-3.0`    | `(1 3 4 5 6 7 9 6)` | `(1 AND ((3 T0 7) AND ((9 WITHOUT 5) AND 6)))` |

```
> (all -parses '(1 and 3 to 7 and 9 without 5 and 2))
```

| []()     |                     |                                                |
|----------|---------------------|------------------------------------------------|
| `Score`  | `Semantics`         | `(1 AND 3 T0 7 AND 9 WITHOUT 5 AND 2)`         |
| `======` | `================`  | `===================================`          |
| `0.2`    | `(1 3 4 6 7 9 2)`   | `((1 AND (((3 T0 7) AND 9) WITHOUT 5)) AND 2)` |
| `0.2`    | `(1 3 4 6 7 9 2)`   | `(1 AND ((((3 T0 7) AND 9) WITHOUT 5) AND 2))` |
| `0.1`    | `(1 3 4 6 7 9 2)`   | `((((1 AND (3 T0 7)) AND 9) WITHOUT 5) AND 2)` |
| `0.1`    | `(1 3 4 6 7 9 2)`   | `(((1 AND ((3 T0 7) AND 9)) WITHOUT 5) AND 2)` |
| `-2.0`   | `(1 3 4 5 6 7 9 2)` | `(((1 AND (3 T0 7)) AND (9 WITHOUT 5)) AND 2)` |
| `-2.0`   | `(1 3 4 5 6 7 9 2)` | `((1 AND (3 T0 7)) AND ((9 WITHOUT 5) AND 2))` |
| `-2.0`   | `(1 3 4 5 6 7 9)`   | `((1 AND (3 T0 7)) AND (9 WITHOUT (5 AND 2)))` |
| `-2.0`   | `(1 3 4 5 6 7 9 2)` | `((1 AND ((3 T0 7) AND (9 WITHOUT 5))) AND 2)` |
| `-2.0`   | `(1 3 4 5 6 7 9 2)` | `(1 AND (((3 T0 7) AND (9 WITHOUT 5)) AND 2))` |
| `-2.0`   | `(1 3 4 5 6 7 9 2)` | `(1 AND ((3 T0 7) AND ((9 WITHOUT 5) AND 2)))` |
| `-2.0`   | `(1 3 4 5 6 7 9)`   | `(1 AND ((3 T0 7) AND (9 WITHOUT (5 AND 2))))` |
| `-2.8`   | `(1 3 4 6 7 9)`     | `(1 AND (((3 T0 7) AND 9) WITHOUT (5 AND 2)))` |
| `-2.9`   | `(1 3 4 6 7 9)`     | `(((1 AND (3 T0 7)) AND 9) WITHOUT (5 AND 2))` |
| `-2.9`   | `(1 3 4 6 7 9)`     | `((1 AND ((3 T0 7) AND 9)) WITHOUT (5 AND 2))` |

В каждом случае правила предпочтений могут присваивать более высокие баллы более разумным интерпретациям.
Оказывается, в каждом случае все интерпретации с положительными оценками представляют собой один и тот же набор чисел, тогда как интерпретации с отрицательными оценками кажутся хуже.
Просмотр всех оценок в мрачных деталях может представлять академический интерес, но на самом деле нам нужно что-то, чтобы выбрать лучшую интерпретацию.
Следующий код подходит для многих ситуаций.
Он выбирает лучшую функцию подсчета баллов(scorer), если есть уникальный, или запрашивает пользователя, совпадают ли несколько интерпретаций для лучшего результата, и жалуется, если вообще нет действительных синтаксических анализов.
Функция query-user может быть полезна во многих приложениях, но обратите внимание, что meaning использует ее только по умолчанию; программа, у которой был некоторый автоматический способ принятия решений, могла бы предоставить еще одну функцию `tie-breaker`.

```lisp
(defun meaning (words &optional (tie-breaker #'query-user))
  "Choose the single top-ranking meaning for the words."
  (let* ((trees (sort (parser words) #'> :key #'tree-score))
         (best-score (if trees (tree-score (first trees)) 0))
         (best-trees (delete best-score trees
                             :key #'tree-score :test-not #'eql))
         (best-sems (delete-duplicates (mapcar #'tree-sem best-trees)
                                       :test #'equal)))
    (case (length best-sems)
      (0 (format t "~&Sorry, I didn't understand that.") nil)
      (1 (first best-sems))
      (t (funcall tie-breaker best-sems)))))

(defun query-user (choices &optional
                           (header-str "~&Please pick one:")
                           (footer-str "~&Your choice? "))
  "Ask user to make a choice."
  (format *query-io* header-str)
  (loop for choice in choices for i from 1 do
        (format *query-io* "~&~3d: ~a" i choice))
  (format *query-io* footer-str)
  (nth (- (read) 1) choices))
```

Здесь мы видим несколько заключительных примеров:

```lisp
> (meaning '(1 to 5 without 3 and 4))
(1 2 5)
> (meaning '(1 to 5 without 3 and 6))
(1 2 4 5 6)
> (meaning '(1 to 5 without 3 and 6 shuffled))
(6 4 1 2 5)
> (meaning '([ 1 to 5 without [ 3 and 6 ] ] reversed))
(5 4 2 1)
> (meaning '(1 to 5 to 9))
```

`Sorry.
I didn't understand that.`

```lisp
NIL
> (meaning '(1 to 5 without 3 and 7 repeat 2))
Please pick one:
      1: (12 4 5 7 12 4 5 7)
      2: (12 4 5 7 7)
```

`Your choice?
1`

```lisp
(1 2 4 5 7 1 2 4 5 7)
```

```
> (all-parses '(1 to 5 without 3 and 7 repeat 2))
```

| []()         |                         |                                           |
|--------------|-------------------------|-------------------------------------------|
| `Score`      | `Semantics`             | `(1 TO 5 WITHOUT 3 AND 7 REPEAT 2)`       |
| `==========` | `=========`             | `===========================`             |
| `0.3`        | `(1 2 4 5 7 1 2 4 5 7)` | `((((1 TO 5) WITHOUT 3) AND 7) REPEAT 2)` |
| `0.3`        | `(1 2 4 5 7 7)`         | `(((1 TO 5) WITHOUT 3) AND (7 REPEAT 2))` |
| `-2.7`       | `(1 2 4 5 1 2 4 5)`     | `(((1 TO 5) WITHOUT (3 AND 7)) REPEAT 2)` |
| `-2.7`       | `(1 2 4 5)`             | `((1 TO 5) WITHOUT ((3 AND 7) REPEAT 2))` |
| `-2.7`       | `(1 2 4 5)`             | `((1 TO 5) WITHOUT (3 AND (7 REPEAT 2)))` |

Этот последний пример указывает на потенциальную проблему: я не был уверен, какая функция оценки для "repeat" была хорошей, поэтому я оставил ее пустым, по умолчанию она была равна 0, и в итоге мы получили два анализа с одинаковыми баллами.
Этот пример предполагает, что "repeat", вероятно, должен включать в себя `inv-span`, как и другие модификаторы, но, возможно, должны быть задействованы и другие факторы.
Между фразами может быть сложное взаимодействие, и не всегда ясно, где выставить оценку.
Например, нет смысла повторять фразу "without"(без); то есть фраза `(x without (y repeat n))`, вероятно, плохая.
Но scorer  для  "without" уже почти справляется с этим.
Он назначает штраф, если его правый аргумент не является подмножеством его левого аргумента.
К сожалению, повторяющиеся элементы не учитываются в множествах, поэтому, например, список (1 2 3 1 2 3) является подмножеством (1 2 3 4).
Тем не менее, мы могли бы изменить scorer для "without", чтобы вместо этого проверять `sub-bag-p` (не встроенную функцию Common Lisp), и тогда "repeat" не должен был бы иметь дело с этим случаем.

## 19.7 Проблема с правилами структуры фраз без контекста

Фрагмент грамматики английского языка, который мы указали в [раздел 19.2](#s0015), допускает множество неграмматических фраз.
Например, он одинаково доволен как "I liked her"(она мне понравилась), так и  "me liked she.". Следует принять только первое из них; второй следует исключить.
Точно так же наша грамматика не утверждает, что глаголы должны согласовываться со своим подлежащим лично и численно.
И поскольку грамматика не имеет понятия значения, она будет принимать предложения, которые семантически аномальны (или, по крайней мере, необычны), например, "the table liked the man."(столу понравился человек).

Есть также некоторые технические проблемы с контекстно-свободной грамматикой.
Например, можно показать, что никакая контекстно-свободная грамматика не может быть написана для учета языка, состоящего только из строк ABC, AABBCC, AAABBBCCC и т. Д., Где каждая строка имеет равное количество As, Bs и Cs. .
Тем не менее, предложения примерно такой формы появляются (правда, редко) на естественных языках.
Пример: "Robin and Sandy loved and hated Pat and Kim, respectively."(Робин и Сэнди любили и ненавидели Пэт и Ким соответственно). Хотя все еще существуют разногласия по поводу возможности создания естественных языков с помощью контекстно-свободной грамматики, очевидно, что гораздо проще использовать более мощный грамматический формализм.
Например, рассмотрите решение проблемы согласования субъект-предикат.
Это возможно сделать с помощью контекстно-свободного языка, включая такие категории, как singular-NP, plural-NP, singular-VP, и plural-VPP, но гораздо проще расширить грамматический формализм, чтобы разрешить передачу функций между составляющими.

Следует отметить, что контекстно-свободные правила структуры фраз оказались очень полезными для описания языков программирования.
Начиная с Algol 60, этот формализм использовался компьютерными учеными под названием *Backus-NaurForm* (BNF).
В этой книге нас больше интересуют естественные языки, поэтому в следующей главе мы увидим более мощный формализм, известный как *unification grammar*(объединяющая грамматика), который может решить проблему согласования, а также другие трудности.
Более того, *Объединенные/унифицированные грамматики* позволяют естественным образом присоединять семантику к синтаксическому анализу.

## 19.8 История и ссылки

There is a class of parsing algorithms known as *chart parsers* that explicitly cache partial parses and reuse them in constructing larger parses.
Earley's algorithm (1970) is the first example, and Martin [Kay (1980)](B9780080571157500285.xhtml#bb0605) gives a good overview of the field and introduces a data structure, the *chart*, for storing substrings of a parse.
[Winograd (1983)](B9780080571157500285.xhtml#bb1395) gives a complex (five-page) specification of a chart parser.
None of these authors have noticed that one can achieve the same results by augmenting a simple (one-page) parser with memoization.
In fact, it is possible to write a top-down parser that is even more succinct.
(See [exercise 19.3](#p2455) below.)

For a general overview of natural language processing, my preferences (in order) are [Allen 1987](B9780080571157500285.xhtml#bb0030), [Winograd 1983](B9780080571157500285.xhtml#bb1395) or [Gazdar and Mellish 1989](B9780080571157500285.xhtml#bb0445).

## 19.9 Упражнения

**Exercise  19.2 [m-h]** Experiment with the grammar and the parser.
Find sentences it cannot parse correctly, and try to add new syntactic rules to account for them.

**Exercise  19.3 [m-h]** The parser works in a bottom-up fashion.
Write a top-down parser, and compare it to the bottom-up version.
Can both parsers work with the same grammar?
If not, what constraints on the grammar does each parsing strategy impose?

**Exercise  19.4 [h]** Imagine an interface to a dual cassette deck.
Whereas the CD player had one assumed verb, "play," this unit has three explicit verb forms: "record," "play," and "erase." There should also be modifiers "from" and "to," where the object of a "to" is either 1 or 2, indicating which cassette to use, and the object of a "from" is either 1 or 2, or one of the symbols PHONO, CD, or AUX.
It's up to you to design the grammar, but you should allow input something like the following, where I have chosen to generate actual Lisp code as the meaning:

```lisp
> (meaning '(play 1 to 5 from CD shuffled and
                          record 1 to 5 from CD and 1 and 3 and 7 from 1))
(PROGN (PLAY '(15 2 3 4) :FROM 'CD)
              (RECORD '(12345) :FROM 'CD)
              (RECORD '(1 3 7) :FROM '1))
```

This assumes that the functions play and record take keyword arguments (with defaults) for : `from` and : `to`.
You could also extend the grammar to accommodate an automatic timer, with phrases like "at 3:00."

**Exercise  19.5 [m]** In the definition of `permute`, repeated here, why is the :`test # ' eq needed?`

```lisp
(defun permute (bag)
      "Return a random permutation of the given input list."
      (if (null bag)
              nil
              (let ((e (random-elt bag)))
                  (cons e (permute (remove e bag :count 1 :test #'eq))))))
```

**Exercise  19.6 [m]** The definition of `permute` takes *O*(*n*2).
Replace it by an *O*(*n*) algorithm.

## 19.10 Ответы

**Answer 19.1**

```lisp
(defun parser (words)
      "Return all complete parses of a list of words."
      (let* ((table (make-array (+ (length words) 1) :initial-element 0))
                        (parses (parse words (length words) table)))
          (mapcar #'parse-tree (complete-parses parses))))
(defun parse (words num-words table)
```

`      "Bottom-up parse.
returning all parses of any prefix of words."`

```lisp
      (unless (null words)
          (let ((ans (aref table num-words)))
              (if (not (eq ans 0))
                      ans
                      (setf (aref table num-words)
                                    (mapcan #'(lambda (rule)
                                                            (extend-parse (rule-lhs rule)
                                                                                        (list (firstwords))
                                                                                        (rest words) nil
                                                                                        (- num-words 1) table))
                                                        (lexical-rules (first words))))))))
(defun extend-parse (lhs rhs rem needed num-words table)
      "Look for the categories needed to complete the parse."
      (if (null needed)
            ;; If nothing is needed, return this parse and upward extensions
            (let ((parse (make-parse :tree (new-tree lhs rhs) :rem rem)))
                (cons parse
                            (mapcan
                          #'(lambda (rule)
                                          (extend-parse (rule-lhs rule)
                                                                      (list (parse-tree parse))
                                                                        rem (rest (rule-rhs rule))
                                                                        num-words table))
                                  (rules-starting-with lhs))))
              ;; otherwise try to extend rightward
              (mapcan
                  #'(lambda (p)
                          (if (eq (parse-lhs p) (first needed))
                                    (extend-parse lhs (appendl rhs (parse-tree p))
                                                                (parse-rem p) (rest needed)
                                                                (length (parse-rem p)) table)))
                  (parse rem num-words table))))
```

It turns out that, for the Lisp system used in the timings above, this version is no faster than normal memoization.

**Answer 19.3** Actually, the top-down parser is a little easier (shorter) than the bottom-up version.
The problem is that the most straightforward way of implementing a top-down parser does not handle so-called *left recursive* rules-rules of the form `(X -> (X ...))`.
This includes rules we've used, like `(NP -> (NP and NP))`.
The problem is that the parser will postulate an NP, and then postulate that it is of the form `(NP and NP)`, and that the first NPof that expression is ofthe form `(NP and NP)`, and so on.
An infinite structure of NPs is explored before even the first word is considered.

Bottom-up parsers are stymied by rules with null right-hand sides: `(X -> O)`.
Note that I was careful to exclude such rules in my grammars earlier.

```lisp
(defun parser (words &optional (cat 's))
      "Parse a list of words; return only parses with no remainder."
      (mapcar #'parse-tree (compiete-parses (parse words cat))))
(defun parse (tokens start-symbol)
      "Parse a list of tokens, return parse trees and remainders."
      (if (eq (first tokens) start-symbol)
              (list (make-parse :tree (first tokens) :rem (rest tokens)))
              (mapcan #'(lambda (rule)
                                      (extend-parse (lhs rule) nil tokens (rhs rule)))
                                  (rules-for start-symbol))))
(defun extend-parse (lhs rhs rem needed)
      "Parse the remaining needed symbols."
      (if (null needed)
              (list (make-parse :tree (cons lhs rhs) :rem rem))
              (mapcan
                  #'(lambda (p)
                            (extend-parse lhs (append rhs (list (parse-tree p)))
                                                            (parse-rem p) (rest needed)))
                  (parse rem (first needed)))))
(defun rules-for (cat)
      "Return all the rules with category on lhs"
      (find-all cat *grammar* :key #'rule-lhs))
```

**Answer 19.5** If it were omitted, then : test would default `to #'eql`, and it would be possible to remove the "wrong" element from the list.
Consider the list (1.0 1.0) in an implementation where floating-point numbers are `eql` but not `eq`.
if `random-elt` chooses the first 1.0 first, then everything is satisfactory-the resuit list is the same as the input list.
However, if `random-elt` chooses the second 1.0, then the second 1.0 will be the first element of the answer, but `remove` will remove the wrong 1.0!
It will remove the first 1.0, and the final answer will be a list with two pointers to the second 1.0 and none to the first.
In other words, we could have:

```lisp
  > (member (first x) (permute x) :test #'eq)
  NIL
```

**Answer 19.6**

```lisp
(defun permute (bag)
      "Return a random permutation of the bag."
      ;; It is done by converting the bag to a vector, but the
      ;; resuit is always the same type as the input bag.
      (let ((bag-copy (replace (make-array (length bag)) bag))
                  (bag-type (if (listp bag) 'list (type-of bag))))
```

`            (coerce (permute-vector!
bag-copy) bag-type)))`

`(defun permute-vector!
(vector)`

```lisp
      "Destructively permute (shuffle) the vector."
      (loop for i from (length vector) downto 2 do
                  (rotatef (aref vector (- i 1))
                                    (aref vector (random i))))
vector)
```

The answer uses `rotatef`, a relative of `setf` that swaps 2 or more values.
That is, `(rotatef a b)` is like:

```lisp
(let ((temp a))
      (setf a b)
      (setf b temp)
      nil)
```

Rarely, `rotatef` is used with more than two arguments, `(rotatef a b c)` is like:

```lisp
(let ((temp a))
      (setf a b)
      (setf b c)
      (setf c temp)
      nil)
```

----------------------

[1](#xfn0015) Some erroneous expressions are underspecified and may return different results in different implementations, but we will ignore that problem.
!!!(p) {:.ftnote1}

[2](#xfn0020) The number of parses of sentences of this kind is the same as the number of bracketings of a arithmetic expression, or the number of binary trees with a given number of leaves.
The resulting sequence (1,2,5,14,42,...) is known as the Catalan Numbers.
This kind of ambiguity is discussed by [Church and Patil (1982)](B9780080571157500285.xhtml#bb0200) in their article *Coping with Syntactic Ambiguity, or How to Put the Block in the Box on the Table.*
!!!(p) {:.ftnote1}